}##############################        POSDOC JOURNAL. JORGE ALEJANDRO TARANGO YONG         ########################################
##                                                                                                                               ##
## The purpose of this document is to record all (or at least the most) progress I've done during this investigation including:  ##
## - The main authors                                                                                                            ##
## - Record of preliminar meteors database                                                                                       ##
## - List of preliminar GPS stations                                                                                             ##
## - TODO list                                                                                                                   ##
## - Codes used to get graphs and other data                                                                                     ##
##                                                                                                                               ##
###################################################################################################################################

* Authors
- Jorge A. Tarango-Yong
- Mario Rodríguez-Martínez
- Raúl Gutiérrez Zalapa

* Base de datos meteoros (definitivo)						
+ Press C-c C-x C-c for full view. Press q in highlighted text to return to normal
+ Press C-x spc for selecting a rectangle
+ Important note: Some events may be repeated

** GLM database						
+ List of constants:
  - Re: Radius of earth (in km)
  - hG: height of GLM satellites (in km)
  - phiG16: longitude of GLM-16 (in deg)
  - phiG17: longitude of GLM-17 (in deg)
  - A: constant to integrate GLM energy over space (normalized to Rn (see below)) (Jenniskens et al. 2018), doi: 100.1111/maps.13137
  - Rn: Distance from GLM satellite to lightning ellipsoid at nadir
  - rad: degrees to radians conversion factor
  - k: correction factor for considering the contribution of the band pass of GLM over the complete blackbody continuum curve (Jenniskens et al. 2018), doi: 100.1111/maps.13137
#+CONSTANTS: Re=6371 :: hG=35786.02 :: phiG16=-75.2 :: A=1.695e18 :: Rn=35780 :: phiG17=-137.2 :: rad=3.1416/180 :: k=1.018e3
| ID      |      Fecha | Got RINEX | Got Kp index | Got GLM data | T_0 (GLM-16) | T_0 (GLM-17) | dt (GLM-16) | dt (GLM-17) |    dt |   s_dt | Latitud (GLM-16) | Latitud (GLM-17) | Longitud (GLM-16) | Longitud (GLM-17) | Latitud | Longitud | sig_latitude | sig_lon | f(lat, long, long_GLM16) | f(lat, long, long_GLM17) |      GLM-16 energy (J) |      GLM-17-energy (J) | Height (km) | R^2_GLM16 | R^2_GLM17 | Radiated Energy GLM-16 (J) | Radiated Energy GLM-17 (J) | Luminous Efficiency (GLM-16) | Total energy GLM-16 (kT)      | Total energy recallibrated (kT) |
|---------+------------+-----------+--------------+--------------+--------------+--------------+-------------+-------------+-------+--------+------------------+------------------+-------------------+-------------------+---------+----------+--------------+---------+--------------------------+--------------------------+------------------------+------------------------+-------------+-----------+-----------+----------------------------+----------------------------+------------------------------+-------------------------------+---------------------------------|
| GLM-00  | 2019-02-01 | **        |              | **           | 18:17:09.375 | 18:17:09.347 |       2.304 |       2.998 | 2.651 | 0.4907 |             22.4 |             22.5 |             -83.8 |             -83.2 |   22.45 |   -83.50 |        0.071 |   0.424 |               0.99997329 |               0.99984123 |  2.429878301895814e-10 |  2.183467721035116e-09 |          24 |    1.28e9 |    1.28e9 |                    4.19e11 |               1.3478262e17 | 0.093016984 +/- 0.016390791  | 1.0763569 +/- 0.18966796      | 2.0978196 +/- 0.42361329        |
| GLM-01  | 2019-05-23 | **        | **           | **           | 16:36:18.147 | 16:36:18.155 |       0.197 |       0.197 | 0.197 | 0.0000 |             24.3 |             24.3 |            -102.2 |            -101.0 |   24.30 |  -101.60 |        0.000 |   0.849 |               0.99993878 |               0.99991181 |  7.080500719563272e-13 |  4.150638352847435e-13 |          28 |    1.28e9 |    1.28e9 |                     1.22e9 |               2.5621350e13 | 0.047526849 +/- 0.029065558  | 6.1337398e-3 +/- 3.7511548e-3 | 0.011954659 +/- 7.4054404e-3    |
| GLM-02  | 2019-07-18 | **        | **           | **           | 14:30:30.131 | 14:30:30.131 |       0.058 |       0.058 | 0.058 | 0.0000 |             27.2 |             27.2 |            -103.7 |            -102.6 |   27.20 |  -103.15 |        0.000 |   0.778 |               0.99992799 |               0.99991013 | 3.1129787646355764e-13 | 3.0977190648089314e-13 |          72 |    1.28e9 |    1.28e9 |                     5.37e8 |               1.9121816e13 | 0.043246870 +/- 0.029105673  | 2.9670451e-3 +/- 1.9968577e-3 | 5.7827709e-3 +/- 3.9334336e-3   |
| GLM-03  | 2019-08-10 | **        | **           | **           | 11:18:48.726 | 11:18:48.632 |       0.145 |       0.252 | 0.199 | 0.0757 |             21.5 |             21.5 |            -103.1 |            -101.9 |   21.50 |  -102.50 |        0.000 |   0.849 |               0.99994244 |               0.99992074 |  6.210697829444508e-13 | 1.0712309278304778e-12 |          92 |    1.27e9 |    1.27e9 |                     1.06e9 |               6.5609083e13 | 0.046764664 +/- 0.029091689  | 5.4161737e-3 +/- 3.3693312e-3 | 0.010556123 +/- 6.6488245e-3    |
| GLM-04  | 2019-10-03 | **        | **           | **           | 07:55:33.551 | 07:55:33.550 |       0.085 |       0.127 | 0.106 | 0.0297 |             25.6 |             25.7 |             -96.8 |             -95.7 |   25.65 |   -96.25 |        0.071 |   0.778 |               0.99994795 |               0.99988945 |  1.479303483161672e-13 |  2.770259572442234e-13 |          74 |    1.28e9 |    1.28e9 |                     2.55e8 |               1.7100452e13 | 0.039697190 +/- 0.028931137  | 1.5349172e-3 +/- 1.1186409e-3 | 2.9915536e-3 +/- 2.2000998e-3   |
| GLM-05  | 2019-10-09 | **        | **           | **           | 06:08:11.205 | 06:08:11.206 |       0.108 |       0.097 | 0.103 | 0.0078 |             23.6 |             23.6 |            -112.1 |            -111.8 |   23.60 |  -111.95 |        0.000 |   0.212 |               0.99991099 |               0.99994423 | 1.3955176168359046e-12 |  8.595560315017904e-13 |          32 |    1.28e9 |    1.28e9 |                     2.41e9 |               5.3059274e13 | 0.051397217 +/- 0.028813097  | 0.011204229 +/- 6.2810509e-3  | 0.021837042 +/- 0.012429732     |
| GLM-06  | 2019-11-16 | **        | **           | **           | 10:14:13.554 | 10:14:13.656 |       0.102 |       0.103 | 0.103 | 0.0007 |             29.2 |             29.2 |            -103.3 |            -102.0 |   29.20 |  -102.65 |        0.000 |   0.919 |               0.99992381 |               0.99990296 |  4.232787697851629e-13 | 3.9114560059171877e-13 |          82 |    1.27e9 |    1.27e9 |                     7.25e8 |               2.3956276e13 | 0.044765817 +/- 0.029121578  | 3.8698669e-3 +/- 2.5174707e-3 | 7.5423706e-3 +/- 4.9626060e-3   |
| GLM-07  | 2019-11-17 | **        | **           | **           | 15:36:01.594 | 15:36:01.584 |       0.113 |       0.118 | 0.116 | 0.0035 |             31.7 |             31.7 |            -118.5 |            -116.9 |   31.70 |  -117.70 |        0.000 |   1.131 |               0.99986640 |               0.99993426 |  1.449666669545249e-12 |  5.117496236627764e-13 |          88 |    1.27e9 |    1.27e9 |                     2.48e9 |               3.1342844e13 | 0.051566729 +/- 0.028797614  | 0.011491762 +/- 6.4176135e-3  | 0.022397444 +/- 0.012701445     |
| GLM-08  | 2019-11-19 | **        | **           | **           | 07:57:40.100 | 07:57:40.118 |       0.177 |       0.016 | 0.097 | 0.1138 |             20.0 |             20.0 |             -89.2 |             -87.6 |   20.00 |   -88.40 |        0.000 |   1.131 |               0.99997235 |               0.99986730 |  6.833250825127828e-14 | 4.4376146917849163e-14 |          99 |    1.27e9 |    1.27e9 |                     1.17e8 |               2.7178811e12 | 0.036295185 +/- 0.028570234  | 7.7026716e-4 +/- 6.0632597e-4 | 1.5012507e-3 +/- 1.1909667e-3   |
| GLM-09  | 2019-11-26 | **        | **           | **           | 13:23:20.453 | 13:23:20.437 |       0.098 |       0.057 | 0.078 | 0.0290 |             23.9 |             23.9 |            -109.3 |            -108.1 |   23.90 |  -108.70 |        0.000 |   0.849 |               0.99991955 |               0.99993421 |  2.634275895650217e-13 |  8.954477775527033e-14 |          81 |    1.27e9 |    1.27e9 |                     4.51e8 |               5.4842991e12 | 0.042387514 +/- 0.029081403  | 2.5423956e-3 +/- 1.7442974e-3 | 4.9551290e-3 +/- 3.4345742e-3   |
| GLM-10  | 2019-12-04 | **        | **           | **           | 09:42:54.880 | 09:42:54.877 |       0.171 |       0.175 | 0.173 | 0.0028 |             31.5 |             31.5 |            -114.3 |            -113.0 |   31.50 |  -113.65 |        0.000 |   0.919 |               0.99988304 |               0.99992679 |  1.938622765895668e-12 |  1.524757629654727e-12 |          77 |    1.28e9 |    1.28e9 |                     3.34e9 |               9.4121303e13 | 0.053362785 +/- 0.028611628  | 0.014955899 +/- 8.0189333e-3  | 0.029149047 +/- 0.015891049     |
| GLM-11  | 2019-12-15 | **        | **           | **           | 14:50:49.779 | 14:50:49.915 |       0.136 |       0.117 | 0.127 | 0.0134 |             27.7 |             27.7 |            -114.7 |            -113.5 |   27.70 |  -114.10 |        0.000 |   0.849 |               0.99989201 |               0.99993834 |  6.161296992576752e-13 | 2.9770126480938705e-13 |          78 |    1.28e9 |    1.28e9 |                     1.06e9 |               1.8376711e13 | 0.046764664 +/- 0.029091689  | 5.4161737e-3 +/- 3.3693312e-3 | 0.010556123 +/- 6.6488245e-3    |
| GLM-12  | 2019-12-29 | **        | **           | **           | 16:16:35.527 | 16:16:35.598 |       0.071 |       0.052 | 0.062 | 0.0134 |             29.6 |             29.6 |            -117.0 |            -115.7 |   29.60 |  -116.35 |        0.000 |   0.919 |               0.99987829 |               0.99993790 |   2.17488682754591e-13 |   7.41910681307072e-14 |          79 |    1.28e9 |    1.28e9 |                     3.75e8 |               4.5797180e12 | 0.041497433 +/- 0.029044329  | 2.1593079e-3 +/- 1.5113139e-3 | 4.2084911e-3 +/- 2.9746446e-3   |
| GLM-13  | 2020-01-03 | **        | **           | **           | 14:10:17.704 | 14:10:17.584 |       0.119 |       0.107 | 0.113 | 0.0085 |             30.2 |             30.2 |            -118.3 |            -117.0 |   30.20 |  -117.65 |        0.000 |   0.919 |               0.99987150 |               0.99993875 |  6.855139495591029e-13 | 3.1314754237003386e-13 |          74 |    1.28e9 |    1.28e9 |                     1.18e9 |               1.9330190e13 | 0.047344995 +/- 0.029072518  | 5.9554210e-3 +/- 3.6569670e-3 | 0.011607116 +/- 7.2187549e-3    |
| GLM-14  | 2020-01-06 | **        | **           | **           | 16:39:27.920 | 16:39:27.917 |       0.115 |       0.121 | 0.118 | 0.0042 |             31.4 |             31.4 |            -108.9 |            -107.5 |   31.40 |  -108.20 |        0.000 |   0.990 |               0.99990157 |               0.99991333 |  9.521115792786327e-13 |  6.275060969231533e-13 |          81 |    1.27e9 |    1.27e9 |                     1.63e9 |               3.8432516e13 | 0.049137065 +/- 0.028984435  | 7.9265268e-3 +/- 4.6756130e-3 | 0.015448801 +/- 9.2392402e-3    |
| GLM-15  | 2020-01-15 | **        | **           | **           | 15:00:33.695 | 15:00:34.003 |       0.308 |       0.117 | 0.213 | 0.1351 |             19.4 |             19.5 |             -96.2 |             -94.9 |   19.45 |   -95.55 |        0.071 |   0.919 |               0.99996208 |               0.99989934 |  7.533539117646777e-13 |  5.875405258747977e-13 |          93 |    1.27e9 |    1.27e9 |                     1.29e9 |               3.5984767e13 | 0.047832762 +/- 0.029052833  | 6.4441967e-3 +/- 3.9140991e-3 | 0.012559739 +/- 7.7284725e-3    |
| GLM-16  | 2020-02-12 | **        | **           | **           | 09:25:40.508 | 09:25:40.490 |       0.194 |       0.226 | 0.210 | 0.0226 |             18.9 |             18.9 |             -94.1 |             -92.9 |   18.90 |   -93.50 |        0.000 |   0.849 |               0.99996685 |               0.99989238 |  4.662846866251004e-13 |   7.11847788770303e-13 |          90 |    1.27e9 |    1.27e9 |                     7.98e8 |               4.3598144e13 | 0.045262441 +/- 0.029119463  | 4.2127866e-3 +/- 2.7102843e-3 | 8.2107211e-3 +/- 5.3440405e-3   |
| GLM-17  | 2020-03-03 | **        | **           | **           | 12:33:27.284 | 12:33:27.282 |       0.062 |       0.061 | 0.062 | 0.0007 |             18.2 |             18.3 |            -106.8 |            -105.9 |   18.25 |  -106.35 |        0.071 |   0.636 |               0.99993830 |               0.99993901 | 1.7320510377282553e-13 | 1.9590237923737543e-13 |          77 |    1.28e9 |    1.28e9 |                     2.99e8 |               1.2092799e13 | 0.040430567 +/- 0.028983521  | 1.7671194e-3 +/- 1.2667975e-3 | 3.4441157e-3 +/- 2.4922397e-3   |
| GLM-18  | 2020-03-31 | **        | **           | **           | 19:31:52.080 | 19:31:52.103 |       0.145 |       0.064 | 0.105 | 0.0573 |             28.5 |             28.4 |            -112.5 |            -111.6 |   28.45 |  -112.05 |        0.071 |   0.636 |               0.99989777 |               0.99993217 |  4.019331742446309e-13 |  1.087721013104986e-13 |          61 |    1.28e9 |    1.28e9 |                     6.93e8 |               6.7143601e12 | 0.044534027 +/- 0.029121344  | 3.7183118e-3 +/- 2.4314495e-3 | 7.2469897e-3 +/- 4.7924800e-3   |
| GLM-19  | 2020-04-08 | **        | **           | **           | 16:25:28.094 | 16:25:28.182 |       0.185 |       0.054 | 0.120 | 0.0926 |             26.1 |             26.1 |             -94.5 |             -93.3 |   26.10 |   -93.90 |        0.000 |   0.849 |               0.99995111 |               0.99987898 | 2.0687508876245494e-13 |  4.214678296162302e-14 |          78 |    1.28e9 |    1.28e9 |                     3.57e8 |               2.6016660e12 | 0.041263350 +/- 0.029032529  | 2.0673227e-3 +/- 1.4545500e-3 | 4.0292119e-3 +/- 2.8626279e-3   |
| GLM-20  | 2020-04-18 | **        | **           | **           | 17:43:25.270 | 17:43:25.268 |       0.146 |       0.131 | 0.139 | 0.0106 |             29.0 |             29.0 |            -107.2 |            -105.9 |   29.00 |  -106.55 |        0.000 |   0.919 |               0.99991347 |               0.99991553 | 3.1668414423809794e-13 |   3.10458970407003e-13 |          82 |    1.27e9 |    1.27e9 |                     5.42e8 |               1.9014507e13 | 0.043292988 +/- 0.029106660  | 2.9914811e-3 +/- 2.0112269e-3 | 5.8303967e-3 +/- 3.9618242e-3   |
| GLM-21  | 2020-04-20 | **        | **           | **           | 16:05:22.001 | 16:05:22:191 |       0.435 |       0.201 | 0.318 | 0.1655 |             28.1 |             28.2 |             -98.6 |             -97.1 |   28.15 |   -97.85 |        0.071 |   1.061 |               0.99993796 |               0.99988850 | 2.1191121272541304e-12 |  1.825984418477952e-12 |          88 |    1.27e9 |    1.27e9 |                     3.63e9 |               1.1183505e14 | 0.053876193 +/- 0.028551212  | 0.016099569 +/- 8.5318245e-3  | 0.031378060 +/- 0.016913982     |
| GLM-22  | 2020-04-25 | **        | **           | **           | 11:03:09.626 | 11:03:09.530 |       0.265 |       0.380 | 0.323 | 0.0813 |             32.1 |             32.2 |            -112.4 |            -110.8 |   32.15 |  -111.60 |        0.071 |   1.131 |               0.99988799 |               0.99991956 |  1.417340866060915e-12 |  2.232950304524486e-12 |          84 |    1.27e9 |    1.27e9 |                     2.43e9 |               1.3676026e14 | 0.051446089 +/- 0.028808670  | 0.011286478 +/- 6.3201777e-3  | 0.021997346 +/- 0.012507576     |
| GLM-23  | 2020-04-28 | **        | **           | **           | 05:43:16.682 | 05:43:16.676 |       0.801 |       0.818 | 0.810 | 0.0120 |             19.9 |             19.9 |            -110.2 |            -110.0 |   19.90 |  -110.10 |        0.000 |   0.141 |               0.99992479 |               0.99994730 | 1.0178255724628665e-11 |  9.224888665035712e-12 |          29 |    1.28e9 |    1.28e9 |                    1.76e10 |               5.6944036e14 | 0.064601351 +/- 0.026608204  | 0.065099193 +/- 0.026813257   | 0.12687833 +/- 0.053736010      |
| GLM-24  | 2020-05-08 | **        | **           | **           | 10:06:16.988 | 10:06:16.942 |       0.437 |       0.543 | 0.490 | 0.0750 |             21.6 |             21.6 |             -93.0 |             -91.8 |   21.60 |   -92.40 |        0.000 |   0.849 |               0.99996365 |               0.99988273 | 2.2619171697132558e-12 |  6.268410264980247e-12 |          81 |    1.27e9 |    1.27e9 |                     3.87e9 |               3.8391783e14 | 0.054274321 +/- 0.028502180  | 0.017038098 +/- 8.9475634e-3  | 0.033207253 +/- 0.017743607     |
| GLM-25  | 2020-07-15 | **        | **           | **           | 19:58:28.112 | 19:58:28.173 |       0.728 |       0.658 | 0.693 | 0.0495 |             24.0 |             24.0 |            -108.7 |            -108.0 |   24.00 |  -108.35 |        0.000 |   0.495 |               0.99992121 |               0.99993372 | 1.3059874702513091e-12 |  6.913835089355929e-13 |          53 |    1.28e9 |    1.28e9 |                     2.25e9 |               4.2678204e13 | 0.050992773 +/- 0.028848572  | 0.010543345 +/- 5.9647757e-3  | 0.020548979 +/- 0.011800641     |
| GLM-26  | 2020-08-07 | **        | **           | **           | 13:29:57.252 | 13:29:57:071 |       0.167 |       0.159 | 0.163 | 0.0057 |             28.8 |             28.8 |            -106.7 |            -105.4 |   28.80 |  -106.05 |        0.000 |   0.919 |               0.99991548 |               0.99991460 |  8.954331725010835e-13 |  6.352236706573085e-13 |          89 |    1.27e9 |    1.27e9 |                     1.53e9 |               3.8905190e13 | 0.048780602 +/- 0.029005383  | 7.4946061e-3 +/- 4.4563599e-3 | 0.014606987 +/- 8.8040841e-3    |
| GLM-27  | 2020-09-13 | **        | **           | **           | 16:41:59.056 | 16:41:59.051 |       0.178 |       0.189 | 0.184 | 0.0078 |             28.4 |             28.5 |            -114.4 |            -113.1 |   28.45 |  -113.75 |        0.071 |   0.919 |               0.99989129 |               0.99993537 |  6.475592424368523e-13 |  5.786823260661331e-13 |          85 |    1.27e9 |    1.27e9 |                     1.11e9 |               3.5442234e13 | 0.047013197 +/- 0.029084048  | 5.6416707e-3 +/- 3.4901396e-3 | 0.010995616 +/- 6.8881646e-3    |
| GLM-28  | 2020-09-30 | **        | **           | **           | 12:28:11.755 | 12:28:11.748 |       0.094 |       0.105 | 0.100 | 0.0078 |             24.9 |             24.9 |            -111.5 |            -110.3 |   24.90 |  -110.90 |        0.000 |   0.849 |               0.99991010 |               0.99993766 |  8.547862356231333e-13 |   7.27027492615035e-13 |          83 |    1.27e9 |    1.27e9 |                     1.46e9 |               4.4527847e13 | 0.048518595 +/- 0.029019704  | 7.1903359e-3 +/- 4.3006484e-3 | 0.014013965 +/- 8.4951275e-3    |
| GLM-29  | 2020-11-16 | **        | **           | **           | 09:36:04.204 | 09:36:04.187 |       0.386 |       0.405 | 0.396 | 0.0134 |             20.3 |             20.3 |            -101.2 |             -99.9 |   20.30 |  -100.55 |        0.000 |   0.919 |               0.99994952 |               0.99991633 |  3.754678744599022e-12 |  5.319998241614338e-12 |         106 |    1.27e9 |    1.27e9 |                     6.43e9 |               3.2583096e14 | 0.057537621 +/- 0.028030325  | 0.026703218 +/- 0.013008878   | 0.052044572 +/- 0.025868548     |
| GLM-30  | 2020-11-17 | **        | **           | **           | 12:53:41.826 | 12:53:41.816 |       0.385 |       0.422 | 0.404 | 0.0262 |             23.0 |             23.0 |            -103.1 |            -101.8 |   23.00 |  -102.45 |        0.000 |   0.919 |               0.99993934 |               0.99991732 |  4.463608461879112e-12 |  5.623754358386713e-12 |          93 |    1.27e9 |    1.27e9 |                     7.64e9 |               3.4443495e14 | 0.058689901 +/- 0.027834784  | 0.031105309 +/- 0.014752275   | 0.060624247 +/- 0.029367156     |
| GLM-31  | 2020-12-19 | **        | **           | **           | 10:18:14.250 | 10:18:14.614 |       0.328 |       0.485 | 0.407 | 0.1110 |             21.9 |             22.0 |            -102.3 |            -100.9 |   21.95 |  -101.60 |        0.071 |   0.990 |               0.99994368 |               0.99991641 |  4.433293600678048e-12 |  4.773030608716246e-12 |          98 |    1.27e9 |    1.27e9 |                     7.59e9 |               2.9233114e14 | 0.058645602 +/- 0.027842573  | 0.030925082 +/- 0.014681985   | 0.060272985 +/- 0.029225978     |
| GLM-32  | 2020-12-23 | **        | **           | **           | 09:43:01.374 | 09:43:01.375 |       0.147 |       0.149 | 0.148 | 0.0014 |             25.8 |             25.7 |            -111.8 |            -110.7 |   25.75 |  -111.25 |        0.071 |   0.778 |               0.99990697 |               0.99993678 |  7.249906845925338e-13 |  5.998020015149864e-13 |          81 |    1.27e9 |    1.27e9 |                     1.24e9 |               3.6735739e13 | 0.047615805 +/- 0.029061989  | 6.2226460e-3 +/- 3.7979505e-3 | 0.012127937 +/- 7.4982028e-3    |
| GLM-33  | 2020-12-29 | **        | **           | **           | 15:20:54.399 | 15:20:54.282 |       0.117 |       0.119 | 0.118 | 0.0014 |             16.8 |             16.8 |            -102.7 |            -101.7 |   16.80 |  -102.20 |        0.000 |   0.707 |               0.99995182 |               0.99992844 |  7.955155609684707e-13 |  7.937009630068694e-13 |          81 |    1.27e9 |    1.27e9 |                     1.36e9 |               4.8611360e13 | 0.048124321 +/- 0.029039523  | 6.7527214e-3 +/- 4.0747756e-3 | 0.013161054 +/- 8.0470909e-3    |
| GLM-34  | 2021-03-31 | **        | **           | **           | 09:01:17.547 | 09:01:17.978 |       0.971 |       0.535 | 0.753 | 0.3083 |             20.1 |             20.2 |             -93.1 |             -92.8 |   20.15 |   -92.95 |        0.071 |   0.212 |               0.99996639 |               0.99988961 | 3.9079678172826326e-12 |  5.546622984700175e-12 |          24 |    1.28e9 |    1.28e9 |                     6.74e9 |               3.4238581e14 | 0.057850022 +/- 0.027978770  | 0.027839466 +/- 0.013464369   | 0.054259119 +/- 0.026782008     |
| GLM-Ven | 2019-06-22 |           |              | **           | 21:25:45.265 |              |       4.873 |             | 4.873 |        |             14.9 |                  |             -65.8 |                   |   14.90 |   -65.80 |              |         |               0.99998560 |               0.99912677 |   8.09382108655163e-10 |                        |          25 |    1.28e9 |    1.28e9 |                    1.40e12 |                         0. | 0.10685931 +/- 9.5599779e-3  | 3.1305469 +/- 0.28006880      | 6.1014359 +/- 0.81239700        |
#+TBLFM: $10=vmean($8..$9);f3::$11=vsdev($8..$9);f4::$16=vmean($12..$13);f2::$17=vmean($14..$15);f2::$18=vsdev($12..$13);f3::$19=vsdev($14..$15);f3::$20=cos($rad*$12)*cos($rad*($phiG16-$14))::$21=cos($rad*$13)*cos($rad*($phiG17-$15))::$25=2*$Re**2*(1-$20)*2+$Re*$hG*(1-$20)+$hG**2-2*$hG*$20*$24;s3::$26=2*$Re**2*(1-$21)+2*$Re*$hG*(1-$21)+$hG**2-2*$hG*$24*$21;s3::$27=$22*$A*$k*$25/$Rn**2;s3::$28=$23*$A*$k*$26/$Rn::$29=(0.1212+/-0.0043)*($27/4.185e12)**(0.115+/-0.075)::$30=($27/4.185e12)/$29::$31=(1.949+/-0.1922)*$30
 
** AMS Events
+ ---- Event data ---- + ------------------------------- Location --------------------------------------- + ------------------- Time and duration ------------------- + ---------- Direction --------------------- + -----------------------------------  Moving ------------------------------------ + ----------- Brightness and color --------------- + --------------------------- Additional observations -------------------------------- +
| Event ID | AMS event | Address                                       | Latitude | Longitude | Elevation | Local date | Local Time |    UT Date | UT Time | Duration | Moving direction           | Descent angle | Facing azimuth | First azimuth | First elevation | Last azimuth | Last elevation | Stellar magnitude | Color                        | Concurrent sound | Delayed sound | Persistent train | Terminal Flash | Fragmentation |
|----------+-----------+-----------------------------------------------+----------+-----------+-----------+------------+------------+------------+---------+----------+----------------------------+---------------+----------------+---------------+-----------------+--------------+----------------+-------------------+------------------------------+------------------+---------------+------------------+----------------+---------------|
| AMS-01   | 1574-2019 | San Miguel Zinacantepec, State of Mexico (MX) |    19.29 |    -99.74 |   2739.85 | 2019-04-03 |      23:54 | 2019-04-04 |    5:54 |      3.5 | From up left to down right |           171 |         292.72 |        107.18 |              78 |       293.31 |             29 |               -12 | Light blue, light green      | Unknown          | Unknown       | Unknown          | Observed       | Observed      |
|----------+-----------+-----------------------------------------------+----------+-----------+-----------+------------+------------+------------+---------+----------+----------------------------+---------------+----------------+---------------+-----------------+--------------+----------------+-------------------+------------------------------+------------------+---------------+------------------+----------------+---------------|
| AMS-02   |           | Homestead, FL                                 |    25.12 |    -80.92 |      -0.1 | 2019-02-01 |      13:16 | 2019-02-01 |   18:16 |      1.5 | From up left to down right |           120 |            190 |           220 |              15 |          225 |              5 |               -14 | Red, white                   | Unknown          | Yes           | Unknown          | Yes            | No            |
|          |           | North Naples, FL                              |    26.33 |    -81.85 |      1.08 | 2019-02-01 |      13:30 | 2019-02-01 |   18:30 |      1.5 | From up right to down left |           186 |         201.71 |        193.98 |              23 |       201.05 |             16 |               -27 | Orange, red                  | No               | No            | No               | Yes            | No            |
|          |           | Havana, Havana (CU)                           |    23.17 |    -82.24 |      2.88 | 2019-02-01 |      13:30 | 2019-02-01 |   18:30 |      7.5 | From up left to down right |           152 |            260 |           250 |              30 |          260 |                |               -23 | Light Blue, Green, Yellow    | No               | No            | Yes              | Unknown        | Unknown       |
|----------+-----------+-----------------------------------------------+----------+-----------+-----------+------------+------------+------------+---------+----------+----------------------------+---------------+----------------+---------------+-----------------+--------------+----------------+-------------------+------------------------------+------------------+---------------+------------------+----------------+---------------|
| AMS-03   | 1694-2019 | Monterrey, Nuevo León (MX)                    |    25.72 |   -100.36 |     558.3 | 2019-04-09 |      23:30 | 2019-04-10 |    4:30 |      3.5 | From up right to down left |           241 |          44.63 |          63.7 |              73 |        27.72 |             48 |                -7 | Blue, Light Blue             | No               | No            | No               | Yes            | Yes           |
|          |           | Austin, TX                                    |    30.38 |    -97.81 |    232.15 | 2019-04-10 |       1:00 | 2019-04-10 |    6:00 |      1.5 | From down right to up left |           272 |         304.09 |        342.02 |              85 |       253.15 |             85 |               -13 | White                        | No               | No            | No               | Yes            | Yes           |
|----------+-----------+-----------------------------------------------+----------+-----------+-----------+------------+------------+------------+---------+----------+----------------------------+---------------+----------------+---------------+-----------------+--------------+----------------+-------------------+------------------------------+------------------+---------------+------------------+----------------+---------------|
| AMS-04   | 6705-2019 | Ciudad Juárez, Chihuahua (MX)                 |    31.74 |   -106.43 |   1126.85 | 2019-12-19 |      19:01 | 2019-12-20 |    2:01 |      1.5 | From down right to up left |           271 |            270 |           270 |              89 |          270 |             61 |                -5 | White                        | No               | No            | No               | No             | No            |
|----------+-----------+-----------------------------------------------+----------+-----------+-----------+------------+------------+------------+---------+----------+----------------------------+---------------+----------------+---------------+-----------------+--------------+----------------+-------------------+------------------------------+------------------+---------------+------------------+----------------+---------------|
| AMS-05   |  871-2020 | Morelia, Michoacán (MX)                       |    19.68 |   -101.19 |   2042.38 | 2020-02-18 |      20:10 | 2020-02-19 |    2:10 |      3.5 | From down right to up left |           283 |             90 |            90 |              33 |           65 |             19 |               -12 | Dark Purple, Orange          | No               | No            | Yes              | Yes            | No            |
|          |           | Atlixco, Puebla (MX)                          |    18.91 |    -98.45 |   1877.22 | 2020-02-18 |      20:20 | 2020-02-19 |    2:20 |      3.5 | From up left to down right |           120 |            285 |           270 |              25 |          290 |             15 |                -8 | Orange, Yellow, White        | No               | Yes           | No               | Yes            | Unknown       |
|          |           | San Agustín, Jalisco (MX)                     |    20.55 |   -103.46 |   1591.74 | 2020-02-18 |      20:14 | 2020-02-19 |    2:14 |      1.5 | From up right to down left |           225 |            140 |           145 |              20 |          130 |             18 |               -22 | Orange, Yellow, Light Yellow | No               | No            | No               | Yes            | No            |
|----------+-----------+-----------------------------------------------+----------+-----------+-----------+------------+------------+------------+---------+----------+----------------------------+---------------+----------------+---------------+-----------------+--------------+----------------+-------------------+------------------------------+------------------+---------------+------------------+----------------+---------------|
| AMS-06   | 6842-2020 | Laredo, TX                                    |    27.46 |    -99.48 |     136.8 | 2020-11-19 |      21:06 | 2020-11-20 |    3:06 |      3.5 | From up left to down right |           124 |         108.34 |        113.65 |              30 |       102.68 |             31 |               -18 | Orange, red                  | No               | No            | No               | No             | Unknown       |
|          |           | San Pedro Garza García, Nuevo León (MX)       |    25.65 |   -100.42 |    847.13 | 2020-11-19 |      20:55 | 2020-11-20 |    2:55 |      3.5 | From up right to down left |           252 |          92.63 |         86.02 |              41 |        76.17 |             30 |               -13 | Blue, green, orange          | Yes              | unknown       | Yes              | Yes            | Yes           |
|          |           | Rio Grande City, TX                           |    26.56 |    -98.67 |    141.05 | 2020-11-19 |      20:57 | 2020-11-20 |    2:57 |      1.5 | From down left to up right |            67 |         173.16 |         175.6 |              64 |          1.5 |             62 |               -19 |                              | No               | No            | No               | No             | No            |
|----------+-----------+-----------------------------------------------+----------+-----------+-----------+------------+------------+------------+---------+----------+----------------------------+---------------+----------------+---------------+-----------------+--------------+----------------+-------------------+------------------------------+------------------+---------------+------------------+----------------+---------------|
|          |           |                                               |          |           |           |            |            |            |         |          |                            |               |                |               |                 |              |                |                   |                              |                  |               |                  |                |               |

1. We need to convert the local (Alt, Az) to (RA, Dec) to put all the observations in the same reference system and create a trajectory
2. The latitude where the meteor is seen at the zenith correspond with the resulted declination, and with the resulting right ascention, we may estimate the local sidereal time of this point. The difference between the local sidereal time and the local time of the observer may give us the longitude where the event could have been seen at zenith. This matches the trajectories given by GLM
3. Try to estimate altitude by estimating terminal flash position given by two (or more) witnesses via parallax and check if the results make sense

Test meteor: AMS-05 a.k.a "Morelian meteoroid" (Sergeeva et al. 2021)

The right answer:

Initial point:
Lat: 19.5 deg
Lon: -100.983

End point: 
Lat: 19.7
Lon: -100.617

Our answer:
Initial point:

Lat:
Lon:

End point:

Lat:
Lon:
** CNEOS fireballs
| ID     |      Fecha | Start time (UT) | Latitud | Longitud | v (km/s) |    vx |   vy |  vz | Altitud (km) | Energia radiada (J) | Energia total (kT) |
|--------+------------+-----------------+---------+----------+----------+-------+------+-----+--------------+---------------------+--------------------|
| USG-01 | 1995-08-05 |        17:14:10 |    11.6 |   -104.3 |          |       |      |     |              |             20.0e10 |               0.56 |
| USG-02 | 1996-07-12 |        14:04:45 |    20.7 |    -93.6 |          |       |      |     |              |              3.2e10 |               0.11 |
| USG-03 | 1997-10-09 |        18:47:15 |    31.8 |   -106.0 |          |       |      |     |         37.0 |             19.0e10 |               0.53 |
| USG-04 | 2000-01-18 |        08:33:58 |    24.3 |    -94.9 |          |       |      |     |              |              3.5e10 |               0.12 |
| USG-05 | 2000-08-25 |        01:12:25 |    14.5 |   -106.1 |          |       |      |     |              |            138.5e10 |                3.1 |
| USG-06 | 2005-11-15 |        05:19:07 |    26.3 |   -113.4 |          |       |      |     |         32.4 |              2.5e10 |              0.089 |
| USG-07 | 2015-07-19 |        07:06:26 |    20.6 |    -87.6 |     17.8 |   9.4 | 13.0 | 7.8 |         22.0 |              2.3e10 |              0.082 |
| USG-08 | 2019-02-01 |        18:17:10 |    22.5 |    -83.8 |     16.3 |  -2.4 | 13.6 | 8.7 |         23.7 |             57.9e10 |                1.4 |
| USG-09 | 2019-06-22 |        21:25:48 |    14.9 |    -66.2 |     14.9 | -13.4 |  6.0 | 2.5 |         25.0 |            294.7e10 |                6.0 |
| USG-10 | 2020-04-28 |        05:43:17 |    20.1 |   -109.4 |          |       |      |     |              |              2.1e10 |              0.076 |

* TODO list
** Work
  - [X] upload journal.org to github
  - [X] Obtain relevant statistical parameters and graphs
    - [X] Average duration of events (and std)
    - [X] dispersion of latitude and longitude
  - [-] Plot positions of events in a map
    - [X] Add ID numbers to events
    - [ ] More aestetic improvements
    - [X] Add to paper
  - [X] Update table in paper
  - [-] Work in presentation
    - [X] General structure
    - [X] Work in individual sections
      - [X] Introduction
      - [X] Database
      - [X] Preliminary results
      - [X] Future Work
    - [X] Table(s) with GPS stations
    - [X] TEC maps like Chelyabinsk paper
      - [X] Add title, labels and other improvements
      - [X] Deal with No data rows.
      - [X] Download and process with GPS Gopi the remaining events
      - [X] Latitude vs time plots
      - [X] Include previous and next day data
      - [X] Add start time to second panel
    - [X] Get Kp index data
      - [X] Code to plot Kp index for desired dates
      - [X] Obtain graphs for meteors sample
    - [X] Correct typos in meteors data
    - [ ] Work in wavelet transforms
      - [ ] Study paper
      - [ ] Adapt code to our work
    - [-] Compute meteor trajectories with GLM data
      - [X] Download GLM data
      - [X] Plot trajectory into vTEC maps
	- [X] Use stereo data. Use mean for position and standard deviation for error margins
      - [ ] Discard events where the Kp index is too high
      - [ ] Identify ionospheric perturbations in vTEC maps
    - [ ] Try solutions of the 2D wave equation in polar coordinates.
    - [X] Include enrgy otput to meteors table and send to Raul
    - [X] Estimate break point height (taken from bolides descriptions)
    - [X] Fill stations table in paper and give format
    - [ ] Improve quality
    - [ ] Write about meteor properties and the othe stuff i wrote in my report
    - [X] Correct table
    - [ ] Work in graphs TEC vs time and Dst index vs time
    - [ ] Use vTEC data to estimate some scintillation parameter
    - [ ] Create figure where GOES-16 and GOES-17 area coverage is shown
    - [ ] Insert citations where needed
    - [ ] Compute ROTI by downloading 1 Hz data
    - [ ] Use sTEC maps along with vTEC maps
    - [X] Compure rTEC instead of vTEC
    - [ ] Make a new sample with AMS events
    - [ ] Make a sample with USG events
    - [ ] Plot energies vs time (events dates)
    - [ ] Plot Kp index vs time (events dates)
      
** DONE Documentos para ingreso al SNI
   - [ ] Publicaciones
   - [X] Documentación que pruebe que impartí clases en:
     - [X] Liceo
     - [X] ENES
** TODO Documentos renovación posdoc
- [X] Formato de solicitud de beca
  - [X] Datos
  - [X] Resumen
  - [X] Firmas
- [-] Justificación académica
  - [X] Redaccion
  - [ ] Firmas
- [-] Informe del trabajo realizado
  - [X] Redaccion
  - [ ] Firmas
- [-] Proyecto de investigación que se realizará en el nuevo periodo
  - [X] Formato
  - [ ] Firmas
- [-] Programa de actividades con cronograma
  - [X] Cronograma
  - [ ] Firmas
- [X] Copia de los avances de productos obtenidos hasta el momento de la solicitud de renovación.
- [X] Copia de los manuscritos de los productos obtenidos hasta el momento. (O bien especificar razones por las que no se han enviado y fecha probable de envio)
* UNAVCO Data users resposibilities
Responsibilities of the data users when writing scientiﬁc publications include the following: Data users that are identiﬁed in 
the archive (i.e., UNAVCO) as part of an ongoing project should always consult the appropriate PI for permission. *If the data 
user is automatically downloading data from the archive via software, this does not excuse the user from manually checking to 
make sure that the data are not part of an ongoing project. Also, when the data are not part of an ongoing project, the source 
of the data must be cited—not just the data archive but, where appropriate, the PI who collected the data via an appropriate pri-
mary publication, a digital object identiﬁer (DOI), or other method as directed by the data collector.*
* Source of Dst index
World Data Center for Geomagnetism, Kyoto
Dst index service
 operated by
Data Analysis Center for Geomagnetism and Space Magnetism
Graduate School of Science, Kyoto University
Kitashirakawa-Oiwake Cho, Sakyo-ku
Kyoto 606-8502, JAPAN
* UNAVCO Station DOIs
| Station | DOI                               | Cite Article (if apply)                                                                                                                                                                           |
|---------+-----------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| BAR1    | https://doi.org/10.7283/T5668BHN  | https://doi.org/10.1785/0120000912                                                                                                                                                                |
| BLYT    | https://doi.org/10.7283/T5HT2MKK  | https://doi.org/10.1785/0120000912                                                                                                                                                                |
| CN23    | https://doi.org/10.7283/T5Q23XJH  | None available                                                                                                                                                                                    |
| CN25    | https://doi.org/10.7283/T57W69G7  | None available                                                                                                                                                                                    |
| GCFS    | https://doi.org/10.7gcfs283/7ETV-X536 | None available                                                                                                                                                                                    |
| GMPK    | https://doi.org/10.7283/WCHN-H687 | https://doi.org/10.1785/0120000912                                                                                                                                                                |
| GUAT    | https://doi.org/10.7283/KH2R-K704 | https://doi.org/10.1130/GES02243.1                                                                                                                                                                |
| GUAX    | https://doi.org/10.7283/T5GX48T2  | https://doi.org/10.1785/0120000912                                                                                                                                                                |
| IAGX    | https://doi.org/10.7283/DGWN-A627 | None available                                                                                                                                                                                    |
| INEG    | NO DOI were found                 | None available                                                                                                                                                                                    |
| KVTX    | https://doi.org/10.7283/T5J38QH8  | None available                                                                                                                                                                                    |
| MDO1    | NO DOI were found                 | None available                                                                                                                                                                                    |
| MGO5    | NO DOI were found                 | None available                                                                                                                                                                                    |
| MGW3    | no DOI were found                 | None available                                                                                                                                                                                    |
| OXTH    | https://doi.org/10.7283/T5Q81B5V  | None available                                                                                                                                                                                    |
| OXUM    | https://doi.org/10.7283/T5J964RP  | http://dx.doi.org/10.1007/s00024-015-1211-x                                                                                                                                                       |
| P001    | https://doi.org/10.7283/T5DR2SGP  | None available                                                                                                                                                                                    |
| P014    | https://doi.org/10.7283/T5DJ5CMK  | None available                                                                                                                                                                                    |
| P807    | https://doi.org/10.7283/T5TQ5ZKM  | None available                                                                                                                                                                                    |
| PLPX    | https://doi.org/10.7283/T5K64G3T  | None available                                                                                                                                                                                    |
| PTEX    | https://doi.org/10.7283/T5610XBP  | None available                                                                                                                                                                                    |
| RG06    | https://doi.org/10.7283/T5668BFR  | None available                                                                                                                                                                                    |
| SG33    | https://doi.org/10.7283/T50863KQ  | None available                                                                                                                                                                                    |
| TNAM    | https://doi.org/10.7283/T5QF8R4R  | None available                                                                                                                                                                                    |
| TNAT    | https://doi.org/10.7283/T5G15Z4S  | None available                                                                                                                                                                                    |
| TNBA    | https://doi.org/10.7283/T57M0688  | None available                                                                                                                                                                                    |
| TNCC    | https://doi.org/10.7283/T50R9MSK  | None available                                                                                                                                                                                    |
| TNCM    | https://doi.org/10.7283/T5B856FW  | None available                                                                                                                                                                                    |
| TNCN    | https://doi.org/10.7283/T5610XQM  | None available                                                                                                                                                                                    |
| TNCU    | https://doi.org/10.7283/T5V69GV2  | None available                                                                                                                                                                                    |
| TNGF    | https://doi.org/10.7283/T53X851M  | None available                                                                                                                                                                                    |
| TNHM    | https://doi.org/10.7283/T5KP80FV  | None available                                                                                                                                                                                    |
| TNMS    | https://doi.org/10.7283/T56H4FQ5  | None available                                                                                                                                                                                    |
| TNNP    | https://doi.org/10.7283/T5N29V96  | None available                                                                                                                                                                                    |
| TNNX    | https://doi.org/10.7283/T52R3PZ0  | None available                                                                                                                                                                                    |
| TNPP    | https://doi.org/10.7283/T5CC0Z0M  | None available                                                                                                                                                                                    |
| TNSJ    | https://doi.org/10.7283/T59S1PF1  | None available                                                                                                                                                                                    |
| TSFX    | https://doi.org/10.7283/AGEA-2G27 | None available                                                                                                                                                                                    |
| UAGU    | https://doi.org/10.7283/T5513WK7  | None available                                                                                                                                                                                    |
| UCOE    | https://doi.org/10.7283/T51834VW  | http://dx.doi.org/10.1007/s00024-015-1211-x                                                                                                                                                       |
| UGEO    | https://doi.org/10.7283/T58S4N9N  | B. Marquez-Azua, E. Cabral-Cano, F. Correa-Mora and C. DeMets, 2004. A model for Mexican neotectonics based on Nationwide GPS measurements, 1993-2001, Geofisica Internacional, v. 43, p.319-330. |
| UHSL    | https://doi.org/10.7283/T55X271S  | None available                                                                                                                                                                                    |
| UHWL    | https://doi.org/10.7283/T53R0R5P  | None available                                                                                                                                                                                    |
| UNPM    | https://doi.org/10.7283/J1GD-5S40 | None available                                                                                                                                                                                    |
| USMX    | https://doi.org/10.7283/T5W957CQ  | None available                                                                                                                                                                                    |
| UXAL    | https://doi.org/10.7283/T5DJ5D1C  | http://dx.doi.org/10.1007/s00024-015-1211-x                                                                                                                                                       |
| WEPD    | https://doi.org/10.7283/T5NZ85RB  | None available                                                                                                                                                                                    |
| WMOK    | https://doi.org/10.7283/T59021Q6  | None available                                                                                                                                                                                    |
| WWMT    | https://doi.org/10.7283/T5H993F2  | https://doi.org/10.1785/0120000912                                                                                                                                                                |
| YESX    | https://doi.org/10.7283/T5RJ4GPF  | None available                                                                                                                                                                                    |

* Codes
+ Tangle with C-c C-v t
+ Use C-c ' to edit code
b+ Unicode for backets: (if tha key does not work). For entering unicode characters, press C-x 8 RET
  [: U-005B 
  ]: U-005D
  {: U-007B
  }: U-007D

#+NAME: plot_mex_map
#+BEGIN_SRC python :eval no :tangle ./plot_meteors.py

# Mexico map plotter
# The main idea of this program was taken from 
# https://towardsdatascience.com/mapping-with-matplotlib-pandas-geopandas-and-basemap-in-python-d11b57ab5dac
# By Ashwani Dhankhar 
# And the shape file for Mexico from CONABIO
# http://www.conabio.gob.mx/informacion/metadata/gis/destdv250k_2gw.xml?_xsl=/db/meadata/xsl/fgdc_html.xsl&_indent=no

import seaborn as sns
import numpy as np
import pandas as pd
import shapefile as shp
import matplotlib.pyplot as plt
from plotfullmap import plot_map
import argparse
from astropy.table import Table
import glob
import matplotlib.cm as cm


# set figure style
sns.set_style("whitegrid") 
sns.mpl.rc("figure", figsize=(10,6))

# Read shape file of Mexico map
sf = shp.Reader("map.shp")
plot_map(sf)


# Read meteors_database

f = Table.read("meteors_database.tab", format="ascii")
f2 = Table.read("USG_meteors_database.tab", format="ascii")
# plot positions plus uncertainties in the map
GLM_mask = f["ID"] == "GLM-Ven" # We will exclude the Venezolan meteor since it will distort the map
USG_mask = f2["ID"] == "USG-09" # We will exclude the Venezolan meteor since it will distort the map

plt.errorbar(f["Longitud"][~GLM_mask], f["Latitud"][~GLM_mask], xerr=f["sig_lon"][~GLM_mask], yerr=f["sig_latitude"][~GLM_mask], fmt="bo", capsize=3)
plt.plot(f2["Longitud"][~USG_mask], f2["Latitud"][~USG_mask], "go")
# Offset of labels
x_off = [10, 10, 10, -10, -10, -10, 10, 10, -10, 10, 10, -10, -10, 10, 10, 10, 10, 10, 10, 10, -10, -10, 10, 10, 10, -10, 10, -10, -10, 10, -10, 10, -10, 10, 10]
y_off = [10, 10, 10, -10, 10, -10, 10, 10, -10, 10, -10, -10, -10, 10, 10, 10, -10, -10, 10, -10, 10, 10, 10, 10, 10, -10, -10, 10, -10, 10, 10, 10, 10, 10, 10]

x2_off = [10, -10, 10, 10, 10, -10, 10, -10, 10]
y2_off = [10, 10, -10, -10, 10, -10, 10, -10, -10]

for i in range(len(f["ID"][~GLM_mask])):
    plt.annotate(f["ID"][~GLM_mask][i], (f["Longitud"][~GLM_mask][i], f["Latitud"][~GLM_mask][i]), textcoords="offset points", color="w", fontsize="small",
    xytext=(x_off[i], y_off[i]), ha="center", bbox=dict(boxstyle="round", pad=0.5, fc="b", alpha=0.7))
for i in range(len(f2["ID"][~USG_mask])):
    plt.annotate(f2["ID"][~USG_mask][i], (f2["Longitud"][~USG_mask][i], f2["Latitud"][~USG_mask][i]), textcoords="offset points", color="w", fontsize="small",
    xytext=(x2_off[i], y2_off[i]), ha="center", bbox=dict(boxstyle="round", pad=0.5, fc="g", alpha=0.7))

ax = plt.gca()
ax.set_aspect('equal', adjustable='box')

plt.savefig("meteors_map.pdf")

#+END_SRC 

#+NAME: plot_GPS_map
#+BEGIN_SRC python :eval no :tangle ./plot_stations.py

# Mexico map plotter
# The main idea of this program was taken from 
# https://towardsdatascience.com/mapping-with-matplotlib-pandas-geopandas-and-basemap-in-python-d11b57ab5dac
# By Ashwani Dhankhar 
# And the shape file for Mexico from CONABIO
# http://www.conabio.gob.mx/informacion/metadata/gis/destdv250k_2gw.xml?_xsl=/db/meadata/xsl/fgdc_html.xsl&_indent=no

# The goal of this program was settled to plot event trajectory from GLM data and the stations that were used to get the RINEX data 

import seaborn as sns
import numpy as np
import pandas as pd
import shapefile as shp
import matplotlib.pyplot as plt
from plotfullmap import plot_map
import argparse
from astropy.table import Table
import glob
import argparse

# Load desired date from command line

parser = argparse.ArgumentParser(
  description=""" Choose a file to work""")


parser.add_argument('--date', type=str, default='2000-01-01',
				 help='Choose date. Format: yyyy-mm-dd')



cmd_args = parser.parse_args()
date = cmd_args.date


directory = "./data/"+date+"/GLM/"


# set figure style
sns.set_style("whitegrid") 
sns.mpl.rc("figure", figsize=(10,6))

# Read shape file of Mexico map
sf = shp.Reader("map.shp")
plot_map(sf)

# Read stations positions table

stations_pos = Table.read("station_data.tab", format="ascii")

# Load and plot event position
load_meteor_pos = Table.read("meteors_database.tab", format="ascii")
meteor_mask = load_meteor_pos["Fecha"] == date
plt.plot(load_meteor_pos["Longitud"][meteor_mask], load_meteor_pos["Latitud"][meteor_mask], "mo")


# Develop dictionaries with events positions, their respective stations.

dates_stations_dict = {"2019-02-01":("CN15", "CN16", "CN23", "GCFS", "UNPM"), 2019-05-23:("KVTX", "TNCU", "UAGU"), "2019-07-18":("KVTX", "MDO1", "TNCU", "UAGU"), "2019-08-10":("KVTX", "TNCU", "UAGU", "UCOE", "UGEO"), "2019-10-03":("KVTX", "UAGU", "UXAL"), "2019-10-09":("GUAX", "TNBA", "TNHM","TNMS"), "2019-11-17":("GUAX", "TNBA", "PTEX", "TSFX", "TNPP", "P001", "BAR1", "WWMT"), "2019-11-16":("KVTX", "P807", "SG33", "TNCU", "UAGU"), "2019-11-19": ("CN23", "GCFS", "UNPM"), "2019-11-26":("TNBA", "TNHM", "TNMS", "UAGU", "YESX"), "2019-12-04":("GMPK", "IAGX", "P014", "PLPX", "TNHM", "TNPP"), "2019-12-15":("GUAX", "TNBA", "TNCU", "TNHM", "TNMS", "UAGU", "YESX"), "2019-12-29":("BAR1", "BLYT", "GUAX", "P014", "PTEX", "TNBA", "TNHM", "USMX", "WWMT"), "2020-01-03":("BAR1", "BLYT", "GUAX", "P014", "PTEX", "TNBA", "TNHM", "USMX", "WWMT"), "2020-01-06":("P014", "P807", "RG07", "TNCU", "USMX", "YESX"), "2020-01-15":("CN23", "CN25", "OXTH", "TNAT", "TNNX", "UNPM", "UXAL"), "2020-02-12":("CN23", "GUAT", "UNPM", "OXTH", "TNNX", "UXAL"), "2020-03-03":("TNAM", "TNCC", "TNCM", "TNMS"), "2020-03-31":("GUAX", "TNCU", "TNHM", "TNPP"), "2020-04-08":("KVTX", "MGW3", "UHSL", "UNPM", "UXAL"), "2020-04-18":("KVTX", "SG33", "TNCU", "TNHM", "UAGU", "YESX"), "2020-04-20":("KVTX", "MGO5", "MGW3", "P807", "WEPD", "WMOK"), "2020-04-25":("P001", "P014", "RG06", "TNPP", "USMX"), "2020-04-28":("TNCM", "TNNP", "YESX"), "2020-05-08":("KVTX", "MGW3", "UNPM", "UXAL"), "2020-07-15":("GUAX", "INEG", "TNAM", "TNCU", "TNHM", "TNMS", "YESX"), "2020-08-07":("INEG", "KVTX", "MGO5", "SG33", "TNCU", "USMX"), "2020-09-13":("GUAX", "PTEX", "TNHM", "TSFX"), "2020-09-30":("GUAX", "INEG", "TNAM", "TNCU", "TNHM", "USMX"), "2020-11-16":("INEG", "TNAM", "TNCN", "TNGF", "UCOE"), "2020-11-17":("INEG", "P807", "TNAM", "TNCU", "UCOE"), "2020-12-19":("INEG", "TNAM", "TNCU", "UCOE", "UHWL", "UXAL"), "2020-12-23":("GUAX", "PTEX", "TNHM", "TSFX"), "2020-12-29":("TNCN", "TNGF", "TNNX", "TNSJ"), "2021-03-31":("OXUM", "TGMX", "TNNX", "UXAL")}

# Plot stations positions

stations = dates_stations_dict[date]

for station in stations:
    mask = stations_pos["Site"] == station
    plt.plot(stations_pos["Longitude"][mask], stations_pos["Latitude"][mask], "go")
    plt.annotate(station, (stations_pos["Longitude"][mask][0], stations_pos["Latitude"][mask][0]),
			  textcoords="offset points", color="w", xytext=(10, 10), ha="center", bbox=dict(boxstyle="round", pad=0.5, fc="g", alpha=0.7))


# Plot bolide trajectory

GLM16_file = open(directory+"GLM-16-data.csv")
GLM17_file = open(directory+"GLM-17-data.csv")

for i in range(10): # skip unneeded data
    GLM16_file.readline()
    GLM17_file.readline()

GLM16_data = GLM16_file.readlines()
GLM17_data = GLM17_file.readlines()
GLM16_table = Table.read(GLM16_data, format="ascii")
GLM17_table = Table.read(GLM17_data, format="ascii")

f1_longitude, f1_latitude = GLM16_table["longitude"], GLM16_table["latitude"]
f2_longitude, f2_latitude = GLM17_table["longitude"], GLM17_table["latitude"]


fit_coord1 = np.polyfit(f1_longitude, f1_latitude, 1)
fit_coord2 = np.polyfit(f2_longitude, f2_latitude, 1)


poly1 = np.poly1d(fit_coord1)
poly2 = np.poly1d(fit_coord2)

if f1_longitude[-1] > f1_longitude[0]:
    step1 = -2
else:
    step1 = 2

if f2_longitude[-1] > f2_longitude[0]:
    step2 = -2
else:
    step2 = 2
#step = 0.5*(step1+step2)

plt.plot([f1_longitude[0]+step1, f1_longitude[-1]], [poly1(f1_longitude[0]+step1), poly1(f1_longitude[-1])], "r--")
plt.plot([f2_longitude[0]+step2, f2_longitude[-1]], [poly2(f2_longitude[0]+step2), poly2(f2_longitude[-1])], "r--")

#plt.plot([0.5*(f1_longitude[0]+f2_longitude[0])+step, 0.5*(f1_longitude[-1]+f2_longitude[-1])], [0.5*(poly1(f1_longitude[0]-2)+poly2(f2_longitude[0]+step)), 0.5*(poly1(f1_longitude[-1])+poly2(f2_longitude[-1]))], "k", lw=2)
plt.annotate(date, (0.5*(f1_longitude[-1]+f2_longitude[-1]), 0.5*(poly1(f1_longitude[-1])+poly2(f2_longitude[-1]))),
			  textcoords="offset points", color="w", xytext=(10, 10), ha="center", bbox=dict(boxstyle="round", pad=0.5, fc="r", alpha=0.7))

ax = plt.gca()
ax.set_aspect("equal", adjustable="box")
outfolder = "./stations_maps/"
plt.savefig(outfolder+date+"-stations.pdf")
#+END_SRC 

#+NAME: plot_vTEC_map
#+BEGIN_SRC python :eval no :tangle ./plot_vTEC.py

# Mexico map plotter
# The main idea of this program was taken from 
# https://towardsdatascience.com/mapping-with-matplotlib-pandas-geopandas-and-basemap-in-python-d11b57ab5dac
# By Ashwani Dhankhar 
# And the shape file for Mexico from CONABIO
# http://www.conabio.gob.mx/informacion/metadata/gis/destdv250k_2gw.xml?_xsl=/db/meadata/xsl/fgdc_html.xsl&_indent=no

import seaborn as sns
import numpy as np
import pandas as pd
import shapefile as shp
import matplotlib.pyplot as plt
from plotfullmap import plot_map
import argparse
from astropy.table import Table
import glob
import matplotlib.cm as cm
import matplotlib.colors as colors
from scipy.interpolate import interp1d
from midpoint import MidpointNormalize



parser = argparse.ArgumentParser(
    description=""" Choose a file to work""")


parser.add_argument('--date', type=str, default='2000-01-01',
			       help='Choose date. Format: yyyy-mm-dd')

parser.add_argument("--formato", type=str, default="pdf", choices=("pdf", "png", "jpg"), 
                                help="Choose output format")

parser.add_argument("--log", action="store_true", help="Use logarithmic scale for vTEC")

parser.add_argument("--substract", action="store_true", help="substract the median of 27 previous days")
parser.add_argument("--data", type=str, default="vTEC", choices=("vTEC", "sTEC"))

cmd_args = parser.parse_args()
date = cmd_args.date
formato = cmd_args.formato
log = cmd_args.log
substract = cmd_args.substract
datatype = cmd_args.data
directory = "./data/"+date
p_directory = directory + "/previous/"
n_directory = directory+ "/next/"

# set figure style
sns.set_style("whitegrid") 


# Load RINEX capabilities

rinex_files = glob.glob(directory+"/*.Cmn")
std_files = glob.glob(directory+"/*.Std")
load_dirs = [open(rinex_files[i], "r") for i in range(len(rinex_files))]
load_std = [Table.read(std_files[i], format="ascii") for i in range(len(std_files))]


rinex_p = glob.glob(p_directory+"*.Cmn")
std_p = glob.glob(p_directory+"*.Std")
rinex_n = glob.glob(n_directory+"*.Cmn")
std_n = glob.glob(n_directory+"*.Std")

load_dir_p = [open(rinex_p[i], "r") for i in range(len(rinex_p))]
load_std_p = [Table.read(std_p[i], format="ascii") for i in range(len(std_p))]
load_dir_n = [open(rinex_n[i], "r") for i in range(len(rinex_n))]
load_std_n = [Table.read(std_n[i], format="ascii") for i in range(len(std_n))]

if substract ==True:
    load_back = glob.glob(directory+"/*.tab")
    stations_names = []
    stations_files = []
    for l in load_back:
        home, dfolder, fecha, tabfile = l.split("/")
        s_name = tabfile.split("-")[0]
        stations_names.append(s_name)
        stations_files.append(tabfile)
    stations_dict = dict(zip(stations_names, stations_files))

# Plot vTEC map
fig = plt.figure()
ax = fig.add_subplot(3, 2, 3, adjustable="box", aspect="equal")
ax1 = fig.add_subplot(3, 2, 4, adjustable="box")
axp = fig.add_subplot(3, 2, 1, adjustable="box", aspect="equal")
axp1 = fig.add_subplot(3, 2, 2, adjustable="box")
axn = fig.add_subplot(3, 2, 5, adjustable="box", aspect="equal")
axn1 = fig.add_subplot(3, 2, 6, adjustable="box")


# Load and plot event position and start time

load_meteor_pos = Table.read("meteors_database.tab", format="ascii")
meteor_mask = load_meteor_pos["Fecha"] == date
ax.plot(load_meteor_pos["Longitud"][meteor_mask], load_meteor_pos["Latitud"][meteor_mask], "mo")

t0_meteor_1 = load_meteor_pos["T_0 (GLM-16)"][meteor_mask]
t0_meteor_2 = load_meteor_pos["T_0 (GLM-17)"][meteor_mask]
# convert start time from string to float (in hours)
t0_m1_h, t0_m1_m, t0_m1_s = t0_meteor_1[0].split(":")
t0_m2_h, t0_m2_m, t0_m2_s = t0_meteor_2[0].split(":")

t0_m1 = float(t0_m1_h) + float(t0_m1_m)/60. + float(t0_m1_s)/3600.
t0_m2 = float(t0_m2_h) + float(t0_m2_m)/60. + float(t0_m2_s)/3600.

# Load and plot RINEX data

for f, g, fp, gp, fn, gn in zip(load_dirs, load_std, load_dir_p, load_std_p, load_dir_n, load_std_n):
    header = f.readline()
    header_p = fp.readline()
    header_n = fn.readline()
    h1, h2 = header.split(",")
    station = h2.split("\\")[-1][0:4]
    blank = f.readline()
    blank = fp.readline()
    blank = fn.readline()
    s_coords = f.readline()
    s_coords_p = fp.readline()
    s_coords_n = fn.readline()
    s_latitude, s_longitude, s_altitude = s_coords.split()
    blank = f.readline()
    blank = fp.readline()
    blank = fn.readline()
    data  = f.readlines()
    data_p = fp.readlines()
    data_n = fn.readlines()
    obs_tab = Table.read(data, format="ascii")
    obs_tab_p = Table.read(data_p, format="ascii")
    obs_tab_n = Table.read(data_n, format="ascii")
    std_time = g["col1"]
    std_time_p = gp["col1"]
    std_time_n = gn["col1"]
    std_TEC = g["col2"]
    std_TEC_p = gp["col2"]
    std_TEC_n = gn["col2"]
    for i in range(len(obs_tab["Vtec"])): # Replace "-" into NaN since there is no data
        if obs_tab["Vtec"][i] == "-":
            obs_tab["Vtec"][i] = np.nan
    for i in range(len(obs_tab_p["Vtec"])):
        if obs_tab_p["Vtec"][i] == "-":
            obs_tab_p["Vtec"][i] = np.nan
    for i in range(len(obs_tab_n["Vtec"])):
        if obs_tab_n["Vtec"][i] == "-":
            obs_tab_n["Vtec"][i] = np.nan

    for i in range(len(std_TEC)):
        if std_TEC[i] == "-":
            std_TEC[i]=np.nan
    for i in range(len(std_TEC_p)):
        if std_TEC_p[i] == "-":
            std_TEC_p[i]=np.nan
    for i in range(len(std_TEC_n)):
        if std_TEC_n[i] == "-":
            std_TEC_n[i]=np.nan

    mean_TEC_int = interp1d(std_time, std_TEC)
    mean_TEC_int_p = interp1d(std_time_p, std_TEC_p)
    mean_TEC_int_n = interp1d(std_time_n, std_TEC_n)
    cmn_time = obs_tab["Time"]
    cmn_time_p = obs_tab_p["Time"]
    cmn_time_n = obs_tab_n["Time"]
    mask = cmn_time < 0
    mask_p = cmn_time_p < 0
    mask_n = cmn_time_n < 0
    cmn_time[mask] = cmn_time[mask] + 24.
    cmn_time_p[mask_p] = cmn_time_p[mask_p] + 24.0
    cmn_time_n[mask_n] = cmn_time_n[mask_n] + 24.0
    mask2 = cmn_time < max(std_time)
    mask2_p = cmn_time_p < max(std_time_p)
    mask2_n = cmn_time_n < max(std_time_n)
    if substract==True:
        subs_tab = Table.read(directory+"/"+stations_dict[station], format="ascii")
        subs_TEC = subs_tab["Mean vTEC"]
        for i in range(len(subs_TEC)):
            if subs_TEC[i] == "-":
                subs_TEC[i] = np.nan
        subs_TEC_int = interp1d(std_time, subs_TEC) # Maybe substract the mean TEC AND the background TEC is redundant
        if datatype == "vTEC":
            dTEC =  obs_tab["Vtec"][mask2] - subs_TEC_int(cmn_time[mask2])
            dTEC_p = obs_tab_p["Vtec"][mask2_p] -subs_TEC_int(cmn_time_p[mask2_p])
            dTEC_n = obs_tab_n["Vtec"][mask2_n] -subs_TEC_int(cmn_time_n[mask2_n])
        elif datatype == "sTEC":
            dTEC =  obs_tab["Stec"][mask2] - subs_TEC_int(cmn_time[mask2])
            dTEC_p = obs_tab_p["Stec"][mask2_p] -subs_TEC_int(cmn_time_p[mask2_p])
            dTEC_n = obs_tab_n["Stec"][mask2_n] -subs_TEC_int(cmn_time_n[mask2_n])

    else:
        if datatype == "vTEC":
            dTEC = obs_tab["Vtec"][mask2] - mean_TEC_int(cmn_time[mask2])
            dTEC_p = obs_tab_p["Vtec"][mask2_p] - mean_TEC_int_p(cmn_time_p[mask2_p])
            dTEC_n = obs_tab_n["Vtec"][mask2_n] - mean_TEC_int_n(cmn_time_n[mask2_n])
        elif datatype == "sTEC":
            dTEC = obs_tab["Stec"][mask2] - mean_TEC_int(cmn_time[mask2])
            dTEC_p = obs_tab_p["Stec"][mask2_p] - mean_TEC_int_p(cmn_time_p[mask2_p])
            dTEC_n = obs_tab_n["Stec"][mask2_n] - mean_TEC_int_n(cmn_time_n[mask2_n])
    norm = MidpointNormalize(midpoint=0)
    if log ==True: 
        im1 = ax1.scatter(cmn_time[mask2], obs_tab["Lat"][mask2], s=1, c=dTEC, cmap="viridis", alpha=0.6, norm=colors.SymLogNorm(linthresh=0.03, linscale=0.03, base=10))
        im1_p = axp1.scatter(cmn_time_p[mask2_p], obs_tab_p["Lat"][mask2_p], s=1, c=dTEC_p, cmap="viridis", alpha=0.6, norm=colors.SymLogNorm(linthresh=0.03, linscale=0.03, base=10))
        im1_n = axn1.scatter(cmn_time_n[mask2_n], obs_tab_n["Lat"][mask2_n], s=1, c=dTEC_n, cmap="viridis", alpha=0.6, norm=colors.SymLogNorm(linthresh=0.03, linscale=0.03, base=10))
        im=ax.scatter(obs_tab["Lon"][mask2]-360, obs_tab["Lat"][mask2], s=1, c=dTEC, cmap="viridis",alpha=0.6, norm=colors.SymLogNorm(linthresh=0.03, linscale=0.03, base=10))
        im_p = axp.scatter(obs_tab_p["Lon"][mask2_p]-360, obs_tab_p["Lat"][mask2_p], s=1, c=dTEC_p, cmap="viridis", alpha=0.6, norm=colors.SymLogNorm(linthresh=0.03, linscale=0.03, base=10))
        im_n = axn.scatter(obs_tab_n["Lon"][mask2_n]-360, obs_tab_n["Lat"][mask2_n], s=1, c=dTEC_n, cmap="viridis", alpha=0.6, norm=colors.SymLogNorm(linthresh=0.03, linscale=0.03, base=10))
    else:
        im1=ax1.scatter(cmn_time[mask2], obs_tab["Lat"][mask2], s=1, c=dTEC, cmap="viridis", alpha=0.6, norm=norm)
        im1_p = axp1.scatter(cmn_time_p[mask2_p], obs_tab_p["Lat"][mask2_p], s=1, c=dTEC_p, cmap="viridis", alpha=0.6, norm=norm)
        im1_n = axn1.scatter(cmn_time_n[mask2_n], obs_tab_n["Lat"][mask2_n], s=1, c=dTEC_n, cmap="viridis", alpha=0.6, norm=norm)
        im=ax.scatter(obs_tab["Lon"][mask2]-360, obs_tab["Lat"][mask2], s=1, c=dTEC, cmap="viridis",alpha=0.6, norm=norm)
        im_p = axp.scatter(obs_tab_p["Lon"][mask2_p]-360, obs_tab_p["Lat"][mask2_p], s=1, c=dTEC_p, cmap="viridis", alpha=0.6, norm=norm)
        im_n = axn.scatter(obs_tab_n["Lon"][mask2_n]-360, obs_tab_n["Lat"][mask2_n], s=1, c=dTEC_n, cmap="viridis", alpha=0.6, norm=norm)



# Plot bolide trajectory

GLM16_file = open(directory+"/GLM/GLM-16-data.csv")
GLM17_file = open(directory+"/GLM/GLM-17-data.csv")

for i in range(10): # skip unneeded data
    GLM16_file.readline()
    GLM17_file.readline()

GLM16_data = GLM16_file.readlines()
GLM17_data = GLM17_file.readlines()
GLM16_table = Table.read(GLM16_data, format="ascii")
GLM17_table = Table.read(GLM17_data, format="ascii")

f1_longitude, f1_latitude = GLM16_table["longitude"], GLM16_table["latitude"]
f2_longitude, f2_latitude = GLM17_table["longitude"], GLM17_table["latitude"]


fit_coord1 = np.polyfit(f1_longitude, f1_latitude, 1)
fit_coord2 = np.polyfit(f2_longitude, f2_latitude, 1)


poly1 = np.poly1d(fit_coord1)
poly2 = np.poly1d(fit_coord2)
if f1_longitude[-1] > f1_longitude[0]:
    step1 = -20
else:
    step1 = 20

if f2_longitude[-1] > f2_longitude[0]:
    step2 = -20
else:
    step2 = 20
ax.plot([f1_longitude[0]+step1, f1_longitude[-1]], [poly1(f1_longitude[0]+step1), poly1(f1_longitude[-1])], "r--")
ax.plot([f2_longitude[0]+step2, f2_longitude[-1]], [poly2(f2_longitude[0]+step2), poly2(f2_longitude[-1])], "r--")

# Show the interval of time the event started

ax1.axvline(x=t0_m1, ls="--", c="k")
ax1.axvline(x=t0_m2, ls="--", c="k")
ax1.axvspan(min((t0_m1, t0_m2)), max((t0_m1, t0_m2)), alpha=0.5, color="red")

# add the second x-axis 

newlabel = [0, 5, 10, 15, 20, 25]
time_zone_dict = {"2019-05-23":-5, "2019-07-18":-5, "2019-08-10":-5, "2019-10-03":-5, "2019-10-09":-7, "2019-11-16":-6, "2019-11-17":-8, "2019-11-19":-7, "2019-11-26":-5, "2019-12-04":-7, "2019-12-15":-7, "2019-12-29":-8, "2020-01-03":-8, "2020-01-06":-7, "2020-01-15":-6, "2020-02-12":-6, "2020-03-03":-6, "2020-03-31":-7, "2020-04-08":-5, "2020-04-18":-6, "2020-04-20":-5, "2020-04-25":-7, "2020-04-28":-6, "2020-05-08":-5, "2020-07-15":-6, "2020-08-07":-6, "2020-09-13":-7, "2020-09-30":-7, "2020-11-16":-6, "2020-11-17":-6, "2020-12-19":-6, "2020-12-23":-7, "2020-12-29":-6, "2021-03-31":-6}

try:
    local_time = np.array(newlabel) + time_zone_dict[date]
    for i in range(len(local_time)):
        if local_time[i] < 0.:
            local_time[i] = local_time[i] + 24.0
    ax2 = ax1.twiny()
    ax2.set_xticks(newlabel)
    ax2.set_xticklabels(local_time)
    ax2.set_xlim(ax1.get_xlim())

    axp2 = axp1.twiny()
    axp2.set_xticks(newlabel)
    axp2.set_xticklabels(local_time)
    axp2.set_xlabel("Local Time (hours)")
    axp2.set_xlim(axp1.get_xlim())

    axn2 = axn1.twiny()
    axn2.set_xticks(newlabel)
    axn2.set_xticklabels(local_time)
    axn2.set_xlim(axn1.get_xlim())
except KeyError: # if the desired date is not in our dictionaries, send an error message and continue
    print("The entered date is not in the Local Time database, avoid upper x-axis")
# Daytime shaded in light yellow and night time in blue

# local sunrise and sunset dictionaries 

sunrise_p = {"2019-05-23":6+57./60, "2019-07-18":7+14./60, "2019-08-10":7+25./60, "2019-10-03":7+26/60., "2019-10-09":7+16./60, "2019-11-16": 7+18./60, "2019-11-17": 6+19/60., "2019-11-19": 7+ 6./60, "2019-11-26": 6+33/60., "2019-12-04": 7+17./60, "2019-12-15": 7+0./60, "2019-12-29": 6+46/60., "2020-01-03": 6+47./60, "2020-01-06": 7+ 7./60, "2020-01-15": 7+1./60, "2020-02-12": 6+41./60, "2020-03-03": 7+16./60, "2020-03-31": 6+16/60., "2020-04-08": 7+ 4./60, "2020-04-18": 6+37./60, "2020-04-20": 7+3./60, "2020-04-25": 5+44./60, "2020-04-28": 6+50./60, "2020-05-08": 6+42./60, "2020-07-15":6.5, "2020-08-07":6.5, "2020-09-13": 7+14./60, "2020-09-30":7+13./60, "2020-11-16": 6+52./60, "2020-11-17": 7+5./60, "2020-12-19":7+20./60, "2020-12-23": 7+ 1./60, "2020-12-29": 7+19/60., "2021-03-31": 6+ 8./60}


sunset_p = {"2019-05-23":20+24./60, "2019-07-18":20+45./60, "2019-08-10":20+23./60, "2019-10-03":19+17/60., "2019-10-09":19, "2019-11-16":17+52./60, "2019-11-17":16+45/60., "2019-11-19":18+14./60, "2019-11-26":17+19/60., "2019-12-04":17.5, "2019-12-15":20+6./60, "2019-12-29":16+49/60., "2020-01-03":16+53./60, "2020-01-06":17+15./60, "2020-01-15":18+5./60, "2020-02-12":18+10./60, "2020-03-03":19+2./60, "2020-03-31":18+40/60., "2020-04-08":19+42./60, "2020-04-18":19.5, "2020-04-20":20+2./60, "2020-04-25":18+58./60, "2020-04-28":19+47./60, "2020-05-08":19+33./60, "2020-07-15":20, "2020-08-07":19+49./60, "2020-09-13":19+35./60, "2020-09-30":19+8./60, "2020-11-16":17+59./60, "2020-11-17":18+4./60, "2020-12-19":18+5./60, "2020-12-23":17+38./60, "2020-12-29":18+21/60., "2021-03-31":18+23./60}

sunrise = {"2019-05-23":6+56./60, "2019-07-18":7+14./60, "2019-08-10":7+26./60, "2019-10-03":7+27/60., "2019-10-09":7+17./60, "2019-11-16": 7+19./60, "2019-11-17": 6+20/60., "2019-11-19": 7+ 6./60, "2019-11-26": 6+34/60., "2019-12-04": 7+18./60, "2019-12-15": 7+1./60, "2019-12-29": 6+46/60., "2020-01-03": 6+47./60, "2020-01-06": 7+ 7./60, "2020-01-15": 7+1./60, "2020-02-12": 6+41./60, "2020-03-03": 7+15./60, "2020-03-31": 6+15/60., "2020-04-08": 7+ 3./60, "2020-04-18": 6+36./60, "2020-04-20": 7+2./60, "2020-04-25": 5+43./60, "2020-04-28": 6+49./60, "2020-05-08": 6+42./60, "2020-07-15":6.5, "2020-08-07":6.5, "2020-09-13": 7+14./60, "2020-09-30":7+13./60, "2020-11-16": 6+53./60, "2020-11-17": 7+3./60, "2020-12-19":7+19./60, "2020-12-23": 7+ 2./60, "2020-12-29": 7+20/60., "2021-03-31": 6+ 7./60}

sunset = {"2019-05-23":20+25./60, "2019-07-18":20+45./60, "2019-08-10":20+22./60, "2019-10-03":19+16/60., "2019-10-09":18+59./60, "2019-11-16":17+52./60, "2019-11-17":16+45/60., "2019-11-19":18+14./60, "2019-11-26":17+19/60., "2019-12-04":17.5, "2019-12-15":20+5./60, "2019-12-29":16+50/60., "2020-01-03":16+53./60, "2020-01-06":17+15./60, "2020-01-15":18+5./60, "2020-02-12":18+10./60, "2020-03-03":19+2./60, "2020-03-31":18+40/60., "2020-04-08":19+43./60, "2020-04-18":19.5, "2020-04-20":20+3./60, "2020-04-25":18+59./60, "2020-04-28":19+48./60, "2020-05-08":19+34./60, "2020-07-15":20, "2020-08-07":19+49./60, "2020-09-13":19+34./60, "2020-09-30":19+7./60, "2020-11-16":17+59./60, "2020-11-17":18+4./60, "2020-12-19":18+6./60, "2020-12-23":17+39./60, "2020-12-29":18+22/60., "2021-03-31":18+24./60}

sunrise_n= {"2019-05-23":6+56./60, "2019-07-18":7+15./60, "2019-08-10":7+26./60, "2019-10-03":7+27/60., "2019-10-09":7+17./60, "2019-11-16": 7+20./60, "2019-11-17": 6+21/60., "2019-11-19": 7+ 6./60, "2019-11-26": 6+35/60., "2019-12-04": 7+19./60, "2019-12-15": 7+1./60, "2019-12-29": 6+46/60., "2020-01-03": 6+48./60, "2020-01-06": 7+ 7./60, "2020-01-15": 7+8./60, "2020-02-12": 6+40./60, "2020-03-03": 7+14./60, "2020-03-31": 6+13/60., "2020-04-08": 7+ 1./60, "2020-04-18": 6+35./60, "2020-04-20": 7+1./60, "2020-04-25": 5+42./60, "2020-04-28": 6+49./60, "2020-05-08": 6+41./60, "2020-07-15":6.5, "2020-08-07":6.5, "2020-09-13": 7+15./60, "2020-09-30":7+14./60, "2020-11-16": 6+53./60, "2020-11-17": 7+6./60, "2020-12-19":7+20./60, "2020-12-23": 7+ 2./60, "2020-12-29": 7+20/60., "2021-03-31": 6+ 6./60}

sunset_n = {"2019-05-23":20+25./60, "2019-07-18":20+44./60, "2019-08-10":20+21./60, "2019-10-03":19+15/60., "2019-10-09":18+58./60, "2019-11-16":17+52./60, "2019-11-17":16+44/60., "2019-11-19":18+13./60, "2019-11-26":17+19/60., "2019-12-04":17.5, "2019-12-15":20+4./60, "2019-12-29":16+51/60., "2020-01-03":16+54./60, "2020-01-06":17+16./60, "2020-01-15":18+5./60, "2020-02-12":18+10./60, "2020-03-03":19+3./60, "2020-03-31":18+41/60., "2020-04-08":19+44./60, "2020-04-18":19.5, "2020-04-20":20+3./60, "2020-04-25":19, "2020-04-28":19+48./60, "2020-05-08":19+34./60, "2020-07-15":20, "2020-08-07":19+48./60, "2020-09-13":19+33./60, "2020-09-30":19+6./60, "2020-11-16":17+59./60, "2020-11-17":18+4./60, "2020-12-19":18+7./60, "2020-12-23":17+39./60, "2020-12-29":18+22/60., "2021-03-31":18+24./60}


try:
    sunrise_p_UT = sunrise_p[date] - time_zone_dict[date]
    sunset_p_UT = sunset_p[date] - time_zone_dict[date]
    sunrise_UT = sunrise[date] - time_zone_dict[date]
    sunset_UT = sunset[date] - time_zone_dict[date]
    sunrise_n_UT = sunrise_n[date] - time_zone_dict[date]
    sunset_n_UT = sunset_n[date] - time_zone_dict[date]
    axp1.axvspan(0, sunrise_p_UT, alpha=0.1, color="cyan")
    axp1.axvspan(sunrise_p_UT, min(sunset_p_UT, 24.0), alpha=0.1, color="yellow")
    if sunset_p_UT < 24.0:
        axp1.axvspan(sunset_p_UT, 24.0, alpha=0.1, color="cyan")
    ax1.axvspan(max(0, sunset_p_UT-24.0), sunrise_UT, alpha=0.1, color="cyan")
    if sunset_p_UT-24 > 0:
        ax1.axvspan(0, sunset_p_UT-24, alpha=0.1, color="yellow")
    ax1.axvspan(sunrise_UT, min(sunset_UT, 24.0), alpha=0.1, color="yellow")
    if sunset_UT < 24.0:
        ax1.axvspan(sunset_UT, 24.0, alpha=0.1, color="cyan")
    axn1.axvspan(max(0, sunset_UT-24.0), sunrise_n_UT, alpha=0.1, color="cyan")
    if sunset_UT - 24.0 >0:
        axn1.axvspan(0, sunset_UT-24, alpha=0.1, color="yellow")
    axn1.axvspan(sunrise_n_UT, 24.0, alpha=0.1, color="yellow")
except KeyError:
    print("The entered date is not in our current database, avoid day-night shading")
# Plot settings

label = "Detrended {} for {} stations".format(datatype, len(rinex_files))
if log ==True:
    cbar = fig.colorbar(im, ax=ax, ticks=[-1e1, -1, -1e-1, 1e-1, 1, 1e1])
    cbar.ax.minorticks_on()
    cbar_p = fig.colorbar(im_p, ax=axp, ticks=[-1e1, -1, -1e-1, 1e-1, 1, 1e1])
    cbar_p.ax.minorticks_on()
    cbar_n = fig.colorbar(im_n, ax=axn, ticks=[-1e1, -1, -1e-1, 1e-1, 1, 1e1])
    cbar_n.ax.minorticks_on()
    cbar1 = fig.colorbar(im1, ax=ax1, ticks=[-1e1, -1, -1e-1, 1e-1, 1, 1e1])
    cbar1.ax.minorticks_on()
    cbar1_p = fig.colorbar(im1_p, ax=axp1, ticks=[-1e1, -1, -1e-1, 1e-1, 1, 1e1])
    cbar1_p.ax.minorticks_on()
    cbar1_n = fig.colorbar(im1_n, ax=axn1, ticks=[-1e1, -1, -1e-1, 1e-1, 1, 1e1])
    cbar1_n.ax.minorticks_on()
else:
    cbar = fig.colorbar(im, ax=ax)
    cbar_p = fig.colorbar(im_p, ax=axp)
    cbar_n = fig.colorbar(im_n, ax=axn)
    cbar1 = fig.colorbar(im1, ax=ax1)
    cbar1_p = fig.colorbar(im1_p, ax=axp1)
    cbar1_n = fig.colorbar(im1_n, ax=axn1)

cbar.set_label("Delta {} (TECU)".format(datatype))
cbar_p.set_label("Delta {} (TECU)".format(datatype))
cbar_n.set_label("Delta {} (TECU)".format(datatype))
cbar1.set_label("Delta {} (TECU)".format(datatype))
cbar1_p.set_label("Delta {} (TECU)".format(datatype))
cbar1_n.set_label("Delta {} (TECU)".format(datatype))
out_dir = "./vTEC-maps/"
axn.set_xlabel("Longitude (deg)")
ax.set_ylabel("Latitude (deg)")
axp.set_ylabel("Latitude (deg)")
axn.set_ylabel("Latitude (deg)")
axn1.set_xlabel("Universal Time (hours)")
plt.suptitle(date+" {} map".format(datatype))
ax1.set_ylabel("Latitude (deg)")
axp1.set_ylabel("Latitude (deg)")
axn1.set_ylabel("Latitude (deg)")
axp.title.set_text(label + ". Previous day")
axp1.title.set_text(label)
ax.title.set_text(label + ". Event date")
axn.title.set_text(label+". Next day")

fig.set_size_inches(22, 18)


if substract == True:
    if log ==True:
        plt.savefig(out_dir+date+"-{}_logmap_minus_background.".format(datatype)+formato)
    else:
        plt.savefig(out_dir+date+"-{}_map_minus_background.".format(datatype)+formato)
else:
    if log==True:
        plt.savefig(out_dir+date+"-{}_logmap.".format(datatype)+formato)
    else:
        plt.savefig(out_dir+date+"-{}_map.".format(datatype)+formato)

#+END_SRC 

#+NAME: Kp_index
#+BEGIN_SRC python :eval no :tangle ./Kp-index.py

  import numpy as np
  import matplotlib.pyplot as plt
  import argparse

  # Get and plot planetary K index for a determined set of dates

  parser = argparse.ArgumentParser(
	description=""" Choose a file to work""")


  parser.add_argument('--date', type=str, default='2000-01-01',
			help='Choose date. Format: yyyy-mm-dd')

  parser.add_argument('--datep', type=str, default='2000-01-01',
			help='Choose date. Format: yyyy-mm-dd')

  parser.add_argument('--datepp', type=str, default='2000-01-01',
			help='Choose date. Format: yyyy-mm-dd')


  parser.add_argument("--ftpfile", type=str, default="", 
		      help="choose the file with the corresponding Kp index data")


  #Capture data from command line

  cmd_args = parser.parse_args()
  date = cmd_args.date
  datep = cmd_args.datep # Previous day to impact date
  datepp = cmd_args.datepp # 2 days before impact date
  year = date.split("-")[0]
  ftpfile = year+cmd_args.ftpfile+"_DGD.txt"

  # Read and load data from Kp index text file

  f = open(ftpfile, "r")

  ## Skip first 12 rows

  f.readline()
  f.readline()
  f.readline()
  f.readline()
  f.readline()
  f.readline()
  f.readline()
  f.readline()
  f.readline()
  f.readline()
  f.readline()
  f.readline()

  ## Load data

  raw_data = f.readlines()

  # Select desired dates from the whole data

  kp = []

  for d in raw_data:
      k_date = d.split()[0:3]
      kdate = k_date[0]+"-"+ k_date[1]+"-"+k_date[2]
      if((kdate==date)|(kdate==datep)|(kdate==datepp)):
	 kp.append(d.split()[-8:])


  # Reshape array to be unidimensional

  Kp = np.array(kp).reshape(24,)

  # Convert array elements from strings to integers

  Kp = [int(k) for k in Kp]

  # Start plotting. The output will be a bar graph

  ## Set x coords

  x = np.arange(len(Kp))

  ## Plot bar graph
  bar = plt.bar(x, Kp, width=0.5)

  ## Set graph limits
  plt.xlim(-0.5, 24)
  plt.ylim(0, 9)

  ## Set ticks in both axis

  plt.xticks([0, 7.5, 15.5], [datepp, datep, date])
  plt.yticks(np.arange(10))

  ## Set vertical lines at the beginning of each day (00:00 UTC)

  plt.axvline(x=7.5, ls="--", c="k")
  plt.axvline(x=15.5, ls="--", c="k")


  ## Set different color to bars according to Kp index value

  for i in range(24):
      if Kp[i]==4:
	 bar[i].set_color("y")
      elif Kp[i] > 4:
	 bar[i].set_color("r")
      else:
	 bar[i].set_color("g")

  ## Set label to axis and graph title

  plt.ylabel("Kp Index")
  plt.title("Estimated Planetary K Index (3 hours data). Begin {} UTC".format(datepp))

  # Save graph

  plt.savefig("./Kp index/"+date+" Kp index.pdf")

#+END_SRC

#+NAME: TEC vs Time
#+BEGIN_SRC python :eval no :tangle ./TEC_vs_time.py

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from astropy.table import Table
import argparse
import glob

# Goal of this program: Obtain TEC vs time plots and analyze them in order to check if we can derive some kind
# of parameter to quantify the TEC perturbations

# We must recycle a lot of the code lines from plot_vTEC.py

parser = argparse.ArgumentParser(
    description=""" Choose a file to work""")


parser.add_argument('--date', type=str, default='2000-01-01',
				   help='Choose date. Format: yyyy-mm-dd')




cmd_args = parser.parse_args()
date = cmd_args.date


directory = "./data/"+date
p_directory = directory + "/previous/"
n_directory = directory+ "/next/"

# set figure style
sns.set_style("whitegrid") 

# Load RINEX capabilities


std_files = glob.glob(directory+"/*.Std")
load_std = [Table.read(std_files[i], format="ascii") for i in range(len(std_files))]


std_p = glob.glob(p_directory+"*.Std")
std_n = glob.glob(n_directory+"*.Std")

load_std_p = [Table.read(std_p[i], format="ascii") for i in range(len(std_p))]
load_std_n = [Table.read(std_n[i], format="ascii") for i in range(len(std_n))]

# Load backgrond median



# Get the data and plot

fig = plt.figure()
j=1
for f, fp, fn in zip(load_std, load_std_p, load_std_n):
    std_time = f["col1"]
    std_time_p = fp["col1"]
    std_time_n = fn["col1"]
    std_TEC = f["col2"]
    std_TEC_p = fp["col2"]
    std_TEC_n = fn["col2"]

    for i in range(len(std_TEC)):
        if std_TEC[i] == "-":
            std_TEC[i]=np.nan
    for i in range(len(std_TEC_p)):
        if std_TEC_p[i] == "-":
            std_TEC_p[i]=np.nan
    for i in range(len(std_TEC_n)):
        if std_TEC_n[i] == "-":
            std_TEC_n[i]=np.nan

    avg_TEC = np.array([std_TEC_p, std_TEC, std_TEC_n])
    avg_TEC = np.reshape(avg_TEC, len(std_TEC_p)+len(std_TEC)+len(std_TEC_n))

    avg_time = np.array([std_time_p, std_time+24.0, std_time_n+48.0])
    avg_time = np.reshape(avg_time, len(std_time_p)+len(std_time)+len(std_time_n))
    plt.plot(avg_time, avg_TEC)   
    ax.set_ylim(0, 40)

fig.savefig("TEC.pdf")
#+END_SRC

#+NAME: Meteor Energy
#+BEGIN_SRC python :eval no :tangle ./GLM_energy.py

import numpy as np
from astropy.table import Table
import glob

# The goal of this program is to estimate the total energy and peak energy
# from GLM data

# Methodology: sum all the values from the energy column of GLM data and also
# get the maximum value. Both should be outputs of the program

# Get a list of the paths of al GLM data

dates = ["2019-02-01", "2019-05-23", "2019-07-18", "2019-08-10", "2019-10-03", "2019-10-09", "2019-11-16", "2019-11-17", "2019-11-19", "2019-11-26", "2019-12-04", "2019-12-15", "2019-12-29", "2020-01-03", "2020-01-06", "2020-01-15", "2020-02-12", "2020-03-03", "2020-03-31", "2020-04-08", "2020-04-18", "2020-04-20", "2020-04-25", "2020-04-28", "2020-05-08", "2020-07-15", "2020-08-07", "2020-09-13","2020-09-30", "2020-11-16", "2020-11-17", "2020-12-19","2020-12-23", "2020-12-29", "2021-03-31"]

G16_dirs = [] 
G17_dirs = []
root_folder = "./data/"
common_folder = "/GLM/"
for date in dates:
    g16 = glob.glob(root_folder+date+common_folder+"*16*")
    g17 = glob.glob(root_folder+date+common_folder+"*17*")
    G16_dirs.append(g16[0])
    G17_dirs.append(g17[0])
# initialize output arrays
g16_total_energy_array = []
g17_total_energy_array = []


#initialize loop for data adquisition

for g16, g17 in zip(G16_dirs, G17_dirs):
    data16 = open(g16, "r")
    data17 = open(g17, "r")

    for i in range(10): # skip unneded data
        data16.readline()
        data17.readline()

    # gather the table with meteor info
    g16data = data16.readlines()
    g17data = data17.readlines()

    g16table = Table.read(g16data, format="ascii")
    g17table = Table.read(g17data, format="ascii")

    # estimate peak energy and total energy for each satellite
    g16_total_energy = np.sum(g16table["energy (joules)"])
    g16_total_energy_array.append(g16_total_energy)
    g17_total_energy = np.sum(g17table["energy (joules)"])
    g17_total_energy_array.append(g17_total_energy)


print("Date (yyyy-mm-dd)", "GLM-16 total energy (joules)","GLM-17 total energy (joules)")
for date, g16_total, g17_total in zip(dates, g16_total_energy_array, g17_total_energy_array):
    print(date, g16_total, g17_total)
  
#+END_SRC

#+NAME: Change coordinates
#+BEGIN_SRC python :eval no :tangle ./h_to_eq.py

  # This program is aimed to change from horizontal coordinates to equatorial coordinates
  # Horizontal coordinates of events are got from AMS data and equatorial coordinates would give us 
  # the place where the event could be seen at the zenith. If we get an event with two or more
  # witnesses we could find a parallax and thus estimate the altitude

  import numpy as np
  from scipy.optimize import fsolve
  import argparse


  def equations(q, Al, Az, Lat):
      """
      Set of equations to solve
      """

      x, y, z = q
      k1 = np.sin(Az)*np.cos(Al)
      k2 = np.cos(Az)*np.cos(Al)*np.sin(Lat) + np.sin(Al)*np.cos(Lat)
      k3 = -np.cos(Az)*np.cos(Al)*np.cos(Lat) + np.sin(Al)*np.sin(Lat)
      return (x*z - k1, y*z - k2, 1 - z**2 - k3**2) 

  # Input data

  parser = argparse.ArgumentParser(description= "Insert local coordinates of events")
  parser.add_argument("--latitude", type=float, help="Local latitude of observer (in degrees)")
  parser.add_argument("--longitude", type=float, help="Local longitude of observer (in degrees)")
  parser.add_argument("--azimuth", type=float, help="Azimuth of the event (in degrees)")
  parser.add_argument("--altitude", type=float, help="Altitude of the event (in degrees)")
  parser.add_argument("--h0", type=float, default=0, help="Initial guess of hour angle (in degrees)")
  parser.add_argument("-d0", type=float, help="Initial guess of declination (in degrees)")

  cmd_args = parser.parser_args()
  l_latitude = cmd_args.latitude
  azimuth = cmd_args.azimuth
  altitude = cmd_args.altitude
  h0 = cmd_args.h0
  delta0 = cmd_args.d0
  l_longitude = cmd_args.longitude

  # set initial guess

  x0 = np.sin(np.radians(h0))
  y0 = np.cos(np.radians(h0))
  z0 = np.cos(np.radians(delta0))

  # solve the system

  sol = fsolve(equations, (x0, y0, z0), args=(np.radians(altitude), np.radians(azimuth), np.radians(l_latitude)))

  # translate solution into (latitude, longitude)

  latitude = np.degrees(np.arccos(z) -0.5*np.pi) # Arc cosine range is from 0 tp \pi and latitude is shifted 90 degrees

  if x>=0: # if sin(h) is positive, then 0 <= h <= 180
      h = np.arccos(y)
  else: # if sin(h) is negative, then 180 < h < 360
      h = np.arccos(y) + np.pi


  # move to a longitude where h=0 (and thus we may see the event at the zenith)

  longitude = l_longitude - np.degrees(h)
#+END_SRC

#+NAME: Background Average
#+BEGIN_SRC python :eval no :tangle ./background-average.py

import numpy as np
from astropy.table import Table
import glob
import statistics as stats
import argparse

# objetivo del programa: Obtener la curva TEC vs tiempo en diferentes fechas previas al evento
# para una misma estación y obtener ~~un promedio~~ la mediana del comportamiento del TEC y restarlo a los datos
# Observar si hay alguna fluctución inusual que sería nuestra detección.


parser = argparse.ArgumentParser(
    description=""" Choose a file to work""")

parser.add_argument("--station", type=str,
                    default="kvtx",
                    help=" Choose station")

parser.add_argument('--date', type=str, default='2000-01-01',
                    help='Choose date. Format: yyyy-mm-dd')




cmd_args = parser.parse_args()
date = cmd_args.date
station = cmd_args.station

directory = "./data/"+date
b_data = glob.glob(directory+"/background/"+station+"*.Std")



Tec_Matrix = []

for b in b_data:
    Tab = Table.read(b, format="ascii")
    Tec_Matrix.append(Tab["col2"])




m = len(Tec_Matrix) # Number of RINEX files read
n = len(Tec_Matrix[0]) # The number of rows in one Std file
Tec_median = np.zeros(n)

for i in range(0, n):
    guante = []
    for j in range(0, m):
        if Tec_Matrix[j][i]=="-":
            guante.append(np.nan)
        else:
            guante.append(float(Tec_Matrix[j][i]))
    Tec_median[i] = stats.median(guante)

# Create table with the median curve

out_table = Table([Tab["col1"], Tec_median], names=("Time (UT)", "Mean vTEC"))
out_table.write(directory+"/"+station+"-mean-TEC.tab", format="ascii", overwrite=True)
#+END_SRC

#+NAME: Filtering
#+BEGIN_SRC python :eval no :tangle ./filtering_vTEC_maps.py
import seaborn as sns
import numpy as np
import pandas as pd
import shapefile as shp
import matplotlib.pyplot as plt
from plotfullmap import plot_map
import argparse
from astropy.table import Table
import glob
import matplotlib.cm as cm
import matplotlib.colors as colors
from scipy.interpolate import interp1d
from midpoint import MidpointNormalize
from matplotlib.ticker import FormatStrFormatter


# This is a variant of the plot_vTEC.py script which filters the vTEC data several hours before the event
# and serveral hours after the event (terminal input) and plots the PRNs which satisfy those conditions.
# We expect to check if any of the chosen stations detected something related to the meteor pass

parser = argparse.ArgumentParser(
    description=""" Choose a file to work""")


parser.add_argument('--date', type=str, default='2000-01-01',
				 help='Choose date. Format: yyyy-mm-dd')

parser.add_argument("--formato", type=str, default="pdf", choices=("pdf", "png", "jpg"), 
				  help="Choose output format")

parser.add_argument("--log", action="store_true", help="Use logarithmic scale for vTEC")

parser.add_argument("--filtertime", type=float, default=1.0, help="Time filtered after the event")

parser.add_argument("--filterbegins", type=float, default=0.2, help="Time filtered before the event")
parser.add_argument("--data", type=str, default="vTEC", choices=("vTEC", "sTEC", "ROTI"), help="Data type to plot")

cmd_args = parser.parse_args()
date = cmd_args.date
formato = cmd_args.formato
log = cmd_args.log
filtertime = cmd_args.filtertime
filterbegins=cmd_args.filterbegins
datatype = cmd_args.data


directory = "./data/"+date

# set figure style
sns.set_style("whitegrid") 


# Load RINEX capabilities

rinex_files = glob.glob(directory+"/*.Cmn")
std_files = glob.glob(directory+"/*.Std")
load_dirs = [open(rinex_files[i], "r") for i in range(len(rinex_files))]
load_std = [Table.read(std_files[i], format="ascii") for i in range(len(std_files))]
#load_ROTI = glob.glob(directory+"/ROTI*")
ROTI_files=[Table.read(load_ROTI[i], format="ascii") for i in range(len(load_ROTI))]

load_back = glob.glob(directory+"/*TEC.tab")
stations_names = []
stations_files = []
for l in load_back:
    home, dfolder, fecha, tabfile = l.split("/")
    s_name = tabfile.split("-")[0]
    stations_names.append(s_name)
    stations_files.append(tabfile)
stations_dict = dict(zip(stations_names, stations_files))

# Plot vTEC map
fig = plt.figure()
ax = fig.add_subplot(1, 2, 1, adjustable="box", aspect="equal")
ax1 = fig.add_subplot(1, 2, 2, adjustable="box")


# Load and plot event position and start time

load_meteor_pos = Table.read("meteors_database.tab", format="ascii")
meteor_mask = load_meteor_pos["Fecha"] == date
ax.plot(load_meteor_pos["Longitud"][meteor_mask], load_meteor_pos["Latitud"][meteor_mask], "mo")

t0_meteor_1 = load_meteor_pos["T_0 (GLM-16)"][meteor_mask]
t0_meteor_2 = load_meteor_pos["T_0 (GLM-17)"][meteor_mask]

t0_m1_h, t0_m1_m, t0_m1_s = t0_meteor_1[0].split(":")
t0_m2_h, t0_m2_m, t0_m2_s = t0_meteor_2[0].split(":")

t0_m1 = float(t0_m1_h) + float(t0_m1_m)/60. + float(t0_m1_s)/3600.
t0_m2 = float(t0_m2_h) + float(t0_m2_m)/60. + float(t0_m2_s)/3600.

# Load and plot RINEX data

for f, g in zip(load_dirs, load_std):
    header = f.readline()
    h1, h2 = header.split(",")
    station = h2.split("\\")[-1][0:4]
    blank = f.readline()
    s_coords = f.readline()
    s_latitude, s_longitude, s_altitude = s_coords.split()
    blank = f.readline()
    data  = f.readlines()
    obs_tab = Table.read(data, format="ascii")
    std_time = g["col1"]
    std_TEC = g["col2"]
    for i in range(len(obs_tab["Vtec"])): # Replace "-" into NaN since there is no data
       if obs_tab["Vtec"][i] == "-":
           obs_tab["Vtec"][i] = np.nan

    for i in range(len(std_TEC)):
        if std_TEC[i] == "-":
            std_TEC[i]=np.nan

    mean_TEC_int = interp1d(std_time, std_TEC)
    cmn_time = obs_tab["Time"]
    mask = cmn_time < 0
    cmn_time[mask] = cmn_time[mask] + 24.
    mask2 = (cmn_time > t0_m1 -filterbegins) & (cmn_time < t0_m1 + filtertime) # Now the mask filters the data in the desired interval time
    subs_tab = Table.read(directory+"/"+stations_dict[station], format="ascii")
    subs_TEC = subs_tab["Mean vTEC"]
    latitude, longitude = obs_tab["Lat"], obs_tab["Lon"]
    for i in range(len(subs_TEC)):
        if subs_TEC[i] == "-":
            subs_TEC[i] = np.nan
    subs_TEC_int = interp1d(std_time, subs_TEC) # Maybe substract the mean TEC AND the background TEC is redundant
    if datatype == "vTEC":
        dTEC =  obs_tab["Vtec"][mask2] - subs_TEC_int(cmn_time[mask2])
    elif datatype == "sTEC":
        dTEC = obs_tab["Stec"][mask2] - subs_TEC_int(cmn_time[mask2])
    norm = MidpointNormalize(midpoint=0)
    if log ==True: 
        im1 = ax1.scatter(cmn_time[mask2], latitude[mask2], s=1, c=dTEC[mask2], cmap="viridis", alpha=0.6, norm=colors.SymLogNorm(linthresh=0.03, linscale=0.03, base=10))
        im=ax.scatter(longitude[mask2]-360, longitude[mask2], s=1, c=dTEC[mask2], cmap="viridis",alpha=0.6, norm=colors.SymLogNorm(linthresh=0.03, linscale=0.03, base=10))
    else:
        im1=ax1.scatter(cmn_time[mask2],latitude[mask2], s=1, c=dTEC[mask2], cmap="viridis", alpha=0.6, norm=norm)
        im=ax.scatter(longitude[mask2]-360, latitude[mask2], s=1, c=dTEC[mask2], cmap="viridis",alpha=0.6, norm=norm)

# Plot bolide trajectory

GLM16_file = open(directory+"/GLM/GLM-16-data.csv")
GLM17_file = open(directory+"/GLM/GLM-17-data.csv")

for i in range(10): # skip unneeded data
    GLM16_file.readline()
    GLM17_file.readline()

GLM16_data = GLM16_file.readlines()
GLM17_data = GLM17_file.readlines()
GLM16_table = Table.read(GLM16_data, format="ascii")
GLM17_table = Table.read(GLM17_data, format="ascii")

f1_longitude, f1_latitude = GLM16_table["longitude"], GLM16_table["latitude"]
f2_longitude, f2_latitude = GLM17_table["longitude"], GLM17_table["latitude"]


fit_coord1 = np.polyfit(f1_longitude, f1_latitude, 1)
fit_coord2 = np.polyfit(f2_longitude, f2_latitude, 1)


poly1 = np.poly1d(fit_coord1)
poly2 = np.poly1d(fit_coord2)
if f1_longitude[-1] > f1_longitude[0]:
    step1 = -20
else:
    step1 = 20

if f2_longitude[-1] > f2_longitude[0]:
    step2 = -20
else:
    step2 = 20
ax.plot([f1_longitude[0]+step1, f1_longitude[-1]], [poly1(f1_longitude[0]+step1), poly1(f1_longitude[-1])], "r--")
ax.plot([f2_longitude[0]+step2, f2_longitude[-1]], [poly2(f2_longitude[0]+step2), poly2(f2_longitude[-1])], "r--")

# Show the interval of time the event started

ax1.axvline(x=t0_m1, ls="--", c="k")
ax1.axvline(x=t0_m2, ls="--", c="k")
ax1.axvspan(min((t0_m1, t0_m2)), max((t0_m1, t0_m2)), alpha=0.5, color="red")

# add the second x-axis 

#newlabel = [0, 5, 10, 15, 20, 25] Deprecated

time_zone_dict = {"2019-05-23":-5, "2019-07-18":-5, "2019-08-10":-5, "2019-10-03":-5, "2019-10-09":-7, "2019-11-16":-6, "2019-11-17":-8, "2019-11-19":-7, "2019-11-26":-5, "2019-12-04":-7, "2019-12-15":-7, "2019-12-29":-8, "2020-01-03":-8, "2020-01-06":-7, "2020-01-15":-6, "2020-02-12":-6, "2020-03-03":-6, "2020-03-31":-7, "2020-04-08":-5, "2020-04-18":-6, "2020-04-20":-5, "2020-04-25":-7, "2020-04-28":-6, "2020-05-08":-5, "2020-07-15":-6, "2020-08-07":-6, "2020-09-13":-7, "2020-09-30":-7, "2020-11-16":-6, "2020-11-17":-6, "2020-12-19":-6, "2020-12-23":-7, "2020-12-29":-6, "2021-03-31":-6}



# Daytime shaded in light yellow and night time in blue

# local sunrise and sunset dictionaries 

sunrise_p = {"2019-05-23":6+57./60, "2019-07-18":7+14./60, "2019-08-10":7+25./60, "2019-10-03":7+26/60., "2019-10-09":7+16./60, "2019-11-16": 7+18./60, "2019-11-17": 6+19/60., "2019-11-19": 7+ 6./60, "2019-11-26": 6+33/60., "2019-12-04": 7+17./60, "2019-12-15": 7+0./60, "2019-12-29": 6+46/60., "2020-01-03": 6+47./60, "2020-01-06": 7+ 7./60, "2020-01-15": 7+1./60, "2020-02-12": 6+41./60, "2020-03-03": 7+16./60, "2020-03-31": 6+16/60., "2020-04-08": 7+ 4./60, "2020-04-18": 6+37./60, "2020-04-20": 7+3./60, "2020-04-25": 5+44./60, "2020-04-28": 6+50./60, "2020-05-08": 6+42./60, "2020-07-15":6.5, "2020-08-07":6.5, "2020-09-13": 7+14./60, "2020-09-30":7+13./60, "2020-11-16": 6+52./60, "2020-11-17": 7+5./60, "2020-12-19":7+20./60, "2020-12-23": 7+ 1./60, "2020-12-29": 7+19/60., "2021-03-31": 6+ 8./60}


sunset_p = {"2019-05-23":20+24./60, "2019-07-18":20+45./60, "2019-08-10":20+23./60, "2019-10-03":19+17/60., "2019-10-09":19, "2019-11-16":17+52./60, "2019-11-17":16+45/60., "2019-11-19":18+14./60, "2019-11-26":17+19/60., "2019-12-04":17.5, "2019-12-15":20+6./60, "2019-12-29":16+49/60., "2020-01-03":16+53./60, "2020-01-06":17+15./60, "2020-01-15":18+5./60, "2020-02-12":18+10./60, "2020-03-03":19+2./60, "2020-03-31":18+40/60., "2020-04-08":19+42./60, "2020-04-18":19.5, "2020-04-20":20+2./60, "2020-04-25":18+58./60, "2020-04-28":19+47./60, "2020-05-08":19+33./60, "2020-07-15":20, "2020-08-07":19+49./60, "2020-09-13":19+35./60, "2020-09-30":19+8./60, "2020-11-16":17+59./60, "2020-11-17":18+4./60, "2020-12-19":18+5./60, "2020-12-23":17+38./60, "2020-12-29":18+21/60., "2021-03-31":18+23./60}

sunrise = {"2019-05-23":6+56./60, "2019-07-18":7+14./60, "2019-08-10":7+26./60, "2019-10-03":7+27/60., "2019-10-09":7+17./60, "2019-11-16": 7+19./60, "2019-11-17": 6+20/60., "2019-11-19": 7+ 6./60, "2019-11-26": 6+34/60., "2019-12-04": 7+18./60, "2019-12-15": 7+1./60, "2019-12-29": 6+46/60., "2020-01-03": 6+47./60, "2020-01-06": 7+ 7./60, "2020-01-15": 7+1./60, "2020-02-12": 6+41./60, "2020-03-03": 7+15./60, "2020-03-31": 6+15/60., "2020-04-08": 7+ 3./60, "2020-04-18": 6+36./60, "2020-04-20": 7+2./60, "2020-04-25": 5+43./60, "2020-04-28": 6+49./60, "2020-05-08": 6+42./60, "2020-07-15":6.5, "2020-08-07":6.5, "2020-09-13": 7+14./60, "2020-09-30":7+13./60, "2020-11-16": 6+53./60, "2020-11-17": 7+3./60, "2020-12-19":7+19./60, "2020-12-23": 7+ 2./60, "2020-12-29": 7+20/60., "2021-03-31": 6+ 7./60}

sunset = {"2019-05-23":20+25./60, "2019-07-18":20+45./60, "2019-08-10":20+22./60, "2019-10-03":19+16/60., "2019-10-09":18+59./60, "2019-11-16":17+52./60, "2019-11-17":16+45/60., "2019-11-19":18+14./60, "2019-11-26":17+19/60., "2019-12-04":17.5, "2019-12-15":20+5./60, "2019-12-29":16+50/60., "2020-01-03":16+53./60, "2020-01-06":17+15./60, "2020-01-15":18+5./60, "2020-02-12":18+10./60, "2020-03-03":19+2./60, "2020-03-31":18+40/60., "2020-04-08":19+43./60, "2020-04-18":19.5, "2020-04-20":20+3./60, "2020-04-25":18+59./60, "2020-04-28":19+48./60, "2020-05-08":19+34./60, "2020-07-15":20, "2020-08-07":19+49./60, "2020-09-13":19+34./60, "2020-09-30":19+7./60, "2020-11-16":17+59./60, "2020-11-17":18+4./60, "2020-12-19":18+6./60, "2020-12-23":17+39./60, "2020-12-29":18+22/60., "2021-03-31":18+24./60}

sunrise_n= {"2019-05-23":6+56./60, "2019-07-18":7+15./60, "2019-08-10":7+26./60, "2019-10-03":7+27/60., "2019-10-09":7+17./60, "2019-11-16": 7+20./60, "2019-11-17": 6+21/60., "2019-11-19": 7+ 6./60, "2019-11-26": 6+35/60., "2019-12-04": 7+19./60, "2019-12-15": 7+1./60, "2019-12-29": 6+46/60., "2020-01-03": 6+48./60, "2020-01-06": 7+ 7./60, "2020-01-15": 7+8./60, "2020-02-12": 6+40./60, "2020-03-03": 7+14./60, "2020-03-31": 6+13/60., "2020-04-08": 7+ 1./60, "2020-04-18": 6+35./60, "2020-04-20": 7+1./60, "2020-04-25": 5+42./60, "2020-04-28": 6+49./60, "2020-05-08": 6+41./60, "2020-07-15":6.5, "2020-08-07":6.5, "2020-09-13": 7+15./60, "2020-09-30":7+14./60, "2020-11-16": 6+53./60, "2020-11-17": 7+6./60, "2020-12-19":7+20./60, "2020-12-23": 7+ 2./60, "2020-12-29": 7+20/60., "2021-03-31": 6+ 6./60}

sunset_n = {"2019-05-23":20+25./60, "2019-07-18":20+44./60, "2019-08-10":20+21./60, "2019-10-03":19+15/60., "2019-10-09":18+58./60, "2019-11-16":17+52./60, "2019-11-17":16+44/60., "2019-11-19":18+13./60, "2019-11-26":17+19/60., "2019-12-04":17.5, "2019-12-15":20+4./60, "2019-12-29":16+51/60., "2020-01-03":16+54./60, "2020-01-06":17+16./60, "2020-01-15":18+5./60, "2020-02-12":18+10./60, "2020-03-03":19+3./60, "2020-03-31":18+41/60., "2020-04-08":19+44./60, "2020-04-18":19.5, "2020-04-20":20+3./60, "2020-04-25":19, "2020-04-28":19+48./60, "2020-05-08":19+34./60, "2020-07-15":20, "2020-08-07":19+48./60, "2020-09-13":19+33./60, "2020-09-30":19+6./60, "2020-11-16":17+59./60, "2020-11-17":18+4./60, "2020-12-19":18+7./60, "2020-12-23":17+39./60, "2020-12-29":18+22/60., "2021-03-31":18+24./60}

sunrise_p_UT = sunrise_p[date] - time_zone_dict[date]
sunset_p_UT = sunset_p[date] - time_zone_dict[date]
sunrise_UT = sunrise[date] - time_zone_dict[date]
sunset_UT = sunset[date] - time_zone_dict[date]
sunrise_n_UT = sunrise_n[date] - time_zone_dict[date]
sunset_n_UT = sunset_n[date] - time_zone_dict[date]



ax1.axvspan(max(0, sunset_p_UT-24.0), sunrise_UT, alpha=0.1, color="cyan")
if sunset_p_UT-24 > 0:
    ax1.axvspan(0, sunset_p_UT-24, alpha=0.1, color="yellow")
ax1.axvspan(sunrise_UT, min(sunset_UT, 24.0), alpha=0.1, color="yellow")
if sunset_UT < 24.0:
    ax1.axvspan(sunset_UT, 24.0, alpha=0.1, color="cyan")

label = "Detrended TEC for {} stations".format(len(rinex_files))
if log ==True:
    cbar = fig.colorbar(im, ax=ax, ticks=[-1e1, -1, -1e-1, 1e-1, 1, 1e1])
    cbar.ax.minorticks_on()
    cbar1 = fig.colorbar(im1, ax=ax1, ticks=[-1e1, -1, -1e-1, 1e-1, 1, 1e1])
    cbar1.ax.minorticks_on()
else:
    cbar = fig.colorbar(im, ax=ax)
    cbar1 = fig.colorbar(im1, ax=ax1)

cbar.set_label("Delta {} (TECU)".format(datatype))
cbar1.set_label("Delta {} (TECU)".format(datatype))
if datatype=="ROTI":
    cbar.set_label(r"ROTI ($TECU~s^{-1}$)")
    cbar1.set_label(r"ROTI ($TECU~s^{-1}$)")
out_dir = "./vTEC-maps/"

ax.set_ylabel("Latitude (deg)")
ax1.set_xlabel("Universal Time (hours)")
plt.suptitle(date+" {} map".format(datatype))
ax1.set_ylabel("Latitude (deg)")
ax.title.set_text(label + ". Event date")
ax1.set_xlim(t0_m1 -filterbegins, t0_m1 + filtertime) # Change creation of second axis after setting xlim of original axis
oldlabel = ax1.get_xticks()
local_time = np.array(oldlabel) + time_zone_dict[date]
for i in range(len(local_time)):
    if local_time[i] < 0.:
        local_time[i] = local_time[i] + 24.0
ax2 = ax1.twiny()
ax2.set_xticks(oldlabel)
ax2.set_xticklabels(local_time)
ax2.set_xlabel("Local Time (hours)")
ax2.set_xlim(ax1.get_xlim())
ax1.xaxis.set_major_formatter(FormatStrFormatter("%.2f"))
ax2.xaxis.set_major_formatter(FormatStrFormatter("%.2f"))
fig.set_size_inches(11, 9)
fig.tight_layout()

if log==True:
    plt.savefig(out_dir+date+"-{}_logmap_filtered+{}-{}.".format(datatype, filtertime, filterbegins)+formato)
else:
    plt.savefig(out_dir+date+"-{}_map_filtered+{}-{}.".format(datatype, filtertime, filterbegins)+formato)
#+END_SRC

#+NAME: ROTI
#+BEGIN_SRC python :eval no :tangle ./ROTI_estimation.py

# This program is designed to estimate the standard deviation of
# the Rate of TEC (ROTI) from 1 Hz RINEX data for every PRN in a
# *.Cmn file (output of the GPS GOPI software where we get TEC 
# calculations from Hatanaka files)

import argparse
import numpy as np
from astropy.table import Table
import glob

# Import parameters from command line -----------------------------------------

parser = argparse.ArgumentParser(
    description=""" Choose a file to work""")


parser.add_argument('--date', type=str, default='2000-01-01',
			       help='Choose date. Format: yyyy-mm-dd')

parser.add_argument("--station", type=str, default="kvtx", 
                                help="Choose station to work")



cmd_args = parser.parse_args()
date = cmd_args.date
station = cmd_args.station

# Read file to work -----------------------------------------------------------

directory = "./data/"+date+"/high-rate/"
pathfile = glob.glob(directory+station+"*.Cmn")
f = open(pathfile[0], "r") #pathfile is an array with one element in this case
f.readline()
f.readline()
f.readline()
f.readline() # The first 4 lines do not contain useful information
data = f.readlines()
Tabdata = Table.read(data, format="ascii")
time = Tabdata["Time"]
time_mask = time < 0
time[time_mask] = time[time_mask] + 24.0 # Fix time values below 0

# Get an array with the available PRNs, set output arrays and loop ----------------

PRNs = np.unique(Tabdata["PRN"])
N = 60 #The ROTI will be computed on a 60 seconds time interval
ROTI = []
outfile = "./data/"+date+"/ROTI-compute_"+station+"_"+date+".tab"
for p in PRNs:
    PRN_mask = Tabdata["PRN"] == p # select only the data of the same PRN
    f_time = np.round(time[PRN_mask]*3600) # time will be measured 
                                           # in seconds and avoid decimals
    f_stec = Tabdata["Stec"][PRN_mask] # the ROTI will be computed using sTEC data
#    t_min, t_max = min(f_time), min(f_time)+N #Define time window where ROTI is 
                                              #computed
    ROT = np.gradient(f_stec)/np.gradient(f_time) #Compute ROT for the whole PRN
    for i in range(N):
        ROTI.append(np.nan) # Before the first minute we can't compute ROTI
    for i in range(len(f_time)-N):
        r_mask = (f_time <= f_time[i+N]) & (f_time >= f_time[i])
        roti = np.std(ROT[r_mask])
        ROTI.append(roti) 

#    while(t_max <= f_time[-1]):#when the upper limit reaches the end, stops this loop
#        r_mask = (f_time <= t_max) & (f_time >= t_min) # This loop won't work because the 1 sec
#        roti = np.std(ROT[r_mask])                     # time interval doesn't follows all the time
#        ROTI.append(roti)
#        t_min = t_min+1
#        t_max = t_max+1 # Shifts the interval time window in 1 second

# Save to a file -------------------------------------------------------------------


outtab = Table([time, Tabdata["PRN"], Tabdata["Az"], Tabdata["Ele"], Tabdata["Lat"], Tabdata["Lon"], Tabdata["Stec"], Tabdata["Vtec"], ROTI], names=("Time", "PRN", "Az", "Ele", "Lat", "Lon", "Stec", "Vtec", "ROTI"))
outtab.write(outfile, format="ascii")    
#+END_SRC

#+NAME: Dst Index
#+BEGIN_SRC python :eval no :tangle ./Dst_index.py

import numpy as np
from astropy.table import Table
import argparse 
import matplotlib.pyplot as plt
import seaborn as sns

# Script goal: Plot Dst index vs time
#                                      WDC for Geomagnetism, Kyoto
#                                Hourly Equatorial Dst Values (REAL-TIME)  

# Read arguments from Terminal and open file

parser = argparse.ArgumentParser(
    description=""" Choose a file to work""")


parser.add_argument('--date', type=str, default='2000-01-01',
			       help='Choose date. Format: yyyy-mm-dd')

cmd_args = parser.parse_args()
date = cmd_args.date
year, month, day = date.split("-")
datafile = "Dst-index-"+month+"-"+year+".txt"
directory = "./Dst index/" 
f = open(directory+datafile, "r")

# Extract information from file

h1 = f.readline()
print(h1)
h2 = f.readline()
print(h2)
h3 = f.readline()
print(h3)
f.readline()
time_str = f.readline()
f.readline()
data = f.readlines()

Tabdata= Table.read(data, format="ascii")
Dst_index = []

mask = Tabdata["col1"]==int(day)
maskp = Tabdata["col1"]==int(day) - 1
# Set the time array for plotting

time = time_str.split()
for i in range(len(time)):
    time[i] = int(time[i])
#time=timep+24
#time_c = np.array([timep, time])
#time_c = np.reshape()
# Set the Dst index array for plotting
for k in Tabdata.keys()[1:]:
    Dst_index.append(Tabdata[k][mask][0])

# Plot Dst-index vs time

sns.set_style("whitegrid")
plt.plot(time, Dst_index)
plt.xlim(0, 24)
plt.ylim(-500, 100)
plt.title("DST (Final)")
plt.text(0, 85, day+" "+h3.lstrip())
plt.text(15, 85, h1.lstrip())
plt.xlabel("Time (UT, hours)")
plt.ylabel("Dst Index (nT)")
outfile = datafile.replace(".txt", ".pdf")
plt.savefig(directory+outfile)
#+END_SRC

#+NAME Plot vTEC maps 2 
#+BEGIN_SRC python :eval no :tangle ./plot_TEC_gradient.py

# Mexico map plotter
# The main idea of this program was taken from 
# https://towardsdatascience.com/mapping-with-matplotlib-pandas-geopandas-and-basemap-in-python-d11b57ab5dac
# By Ashwani Dhankhar 
# And the shape file for Mexico from CONABIO
# http://www.conabio.gob.mx/informacion/metadata/gis/destdv250k_2gw.xml?_xsl=/db/meadata/xsl/fgdc_html.xsl&_indent=no

# This is a clone of the vTEC_maps.py script except in this case we will compute the gradient of TEC instead of substracting the actual TEC from 
# some backgrond (or not?)

import seaborn as sns
import numpy as np
import pandas as pd
import shapefile as shp
import matplotlib.pyplot as plt
from plotfullmap import plot_map
import argparse
from astropy.table import Table
import glob
import matplotlib.cm as cm
import matplotlib.colors as colors
from scipy.interpolate import interp1d
from midpoint import MidpointNormalize


parser = argparse.ArgumentParser(
    description=""" Choose a file to work""")


parser.add_argument('--date', type=str, default='2000-01-01',
			       help='Choose date. Format: yyyy-mm-dd')

parser.add_argument("--formato", type=str, default="pdf", choices=("pdf", "png", "jpg"), 
                                help="Choose output format")

parser.add_argument("--log", action="store_true", help="Use logarithmic scale for vTEC")

parser.add_argument("--substract", action="store_true", help="substract the median of 27 previous days")
parser.add_argument("--data", type=str, default="vTEC", choices=("vTEC", "sTEC"))

cmd_args = parser.parse_args()
date = cmd_args.date
formato = cmd_args.formato
log = cmd_args.log
substract = cmd_args.substract
datatype = cmd_args.data
directory = "./data/"+date
p_directory = directory + "/previous/"
n_directory = directory+ "/next/"

# set figure style
sns.set_style("whitegrid") 


# Load RINEX capabilities

rinex_files = glob.glob(directory+"/*.Cmn")
#std_files = glob.glob(directory+"/*.Std")
load_dirs = [open(rinex_files[i], "r") for i in range(len(rinex_files))]
#load_std = [Table.read(std_files[i], format="ascii") for i in range(len(std_files))]


rinex_p = glob.glob(p_directory+"*.Cmn")
#std_p = glob.glob(p_directory+"*.Std")
rinex_n = glob.glob(n_directory+"*.Cmn")
#std_n = glob.glob(n_directory+"*.Std")

load_dir_p = [open(rinex_p[i], "r") for i in range(len(rinex_p))]
#load_std_p = [Table.read(std_p[i], format="ascii") for i in range(len(std_p))]
load_dir_n = [open(rinex_n[i], "r") for i in range(len(rinex_n))]
#load_std_n = [Table.read(std_n[i], format="ascii") for i in range(len(std_n))]

if substract ==True:
    load_back = glob.glob(directory+"/*.tab")
    stations_names = []
    stations_files = []
    for l in load_back:
        home, dfolder, fecha, tabfile = l.split("/")
        s_name = tabfile.split("-")[0]
        stations_names.append(s_name)
        stations_files.append(tabfile)
    stations_dict = dict(zip(stations_names, stations_files))

# Plot vTEC map
fig = plt.figure()
ax = fig.add_subplot(3, 2, 3, adjustable="box", aspect="equal")
ax1 = fig.add_subplot(3, 2, 4, adjustable="box")
axp = fig.add_subplot(3, 2, 1, adjustable="box", aspect="equal")
axp1 = fig.add_subplot(3, 2, 2, adjustable="box")
axn = fig.add_subplot(3, 2, 5, adjustable="box", aspect="equal")
axn1 = fig.add_subplot(3, 2, 6, adjustable="box")


# Load and plot event position and start time

load_meteor_pos = Table.read("meteors_database.tab", format="ascii")
meteor_mask = load_meteor_pos["Fecha"] == date
ax.plot(load_meteor_pos["Longitud"][meteor_mask], load_meteor_pos["Latitud"][meteor_mask], "mo")

t0_meteor_1 = load_meteor_pos["T_0 (GLM-16)"][meteor_mask]
t0_meteor_2 = load_meteor_pos["T_0 (GLM-17)"][meteor_mask]

t0_m1_h, t0_m1_m, t0_m1_s = t0_meteor_1[0].split(":")
t0_m2_h, t0_m2_m, t0_m2_s = t0_meteor_2[0].split(":")

t0_m1 = float(t0_m1_h) + float(t0_m1_m)/60. + float(t0_m1_s)/3600.
t0_m2 = float(t0_m2_h) + float(t0_m2_m)/60. + float(t0_m2_s)/3600.
#stations = []
# Load and plot RINEX data

for f, fp, fn in zip(load_dirs, load_dir_p, load_dir_n):
    header = f.readline()
    header_p = fp.readline()
    header_n = fn.readline()
    h1, h2 = header.split(",")
    station = h2.split("\\")[-1][0:4]
    blank = f.readline()
    blank = fp.readline()
    blank = fn.readline()
    s_coords = f.readline()
    s_coords_p = fp.readline()
    s_coords_n = fn.readline()
    s_latitude, s_longitude, s_altitude = s_coords.split()
    blank = f.readline()
    blank = fp.readline()
    blank = fn.readline()
    data  = f.readlines()
    data_p = fp.readlines()
    data_n = fn.readlines()
    obs_tab = Table.read(data, format="ascii")
    obs_tab_p = Table.read(data_p, format="ascii")
    obs_tab_n = Table.read(data_n, format="ascii")
#    std_time = g["col1"]
#    std_time_p = gp["col1"]
#    std_time_n = gn["col1"]
#    std_TEC = g["col2"]
#    std_TEC_p = gp["col2"]
#    std_TEC_n = gn["col2"]
    for i in range(len(obs_tab["Vtec"])): # Replace "-" into NaN since there is no data
        if obs_tab["Vtec"][i] == "-":
            obs_tab["Vtec"][i] = np.nan
    for i in range(len(obs_tab_p["Vtec"])):
        if obs_tab_p["Vtec"][i] == "-":
            obs_tab_p["Vtec"][i] = np.nan
    for i in range(len(obs_tab_n["Vtec"])):
        if obs_tab_n["Vtec"][i] == "-":
            obs_tab_n["Vtec"][i] = np.nan

#    for i in range(len(std_TEC)):
#        if std_TEC[i] == "-":
#            std_TEC[i]=np.nan
#    for i in range(len(std_TEC_p)):
#        if std_TEC_p[i] == "-":
#            std_TEC_p[i]=np.nan
#    for i in range(len(std_TEC_n)):
#        if std_TEC_n[i] == "-":
#            std_TEC_n[i]=np.nan

#    mean_TEC_int = interp1d(std_time, std_TEC)
#    mean_TEC_int_p = interp1d(std_time_p, std_TEC_p)
#    mean_TEC_int_n = interp1d(std_time_n, std_TEC_p)
    cmn_time = obs_tab["Time"]
    cmn_time_p = obs_tab_p["Time"]
    cmn_time_n = obs_tab_n["Time"]
    mask = cmn_time < 0
    mask_p = cmn_time_p < 0
    mask_n = cmn_time_n < 0
    cmn_time[mask] = cmn_time[mask] + 24.
    cmn_time_p[mask_p] = cmn_time_p[mask_p] + 24.0
    cmn_time_n[mask_n] = cmn_time_n[mask_n] + 24.0
#    mask2 = cmn_time < max(std_time)
#    mask2_p = cmn_time_p < max(std_time_p)
#    mask2_n = cmn_time_n < max(std_time_n)
    if substract==True:
        subs_tab = Table.read(directory+"/"+stations_dict[station], format="ascii")
        subs_TEC = subs_tab["Mean vTEC"]
        std_time = subs_tab["Time (UT)"]
        mask2 = cmn_time < max(std_time)
        mask2_p = cmn_time_p < max(std_time)
        mask2_n = cmn_time_n < max(std_time)
        for i in range(len(subs_TEC)):
            if subs_TEC[i] == "-":
                subs_TEC[i] = np.nan
        subs_TEC_int = interp1d(std_time, subs_TEC) # Maybe substract the mean TEC AND the background TEC is redundant
        time=cmn_time[mask2]
        time_p = cmn_time_p[mask2_p]
        time_n = cmn_time_n[mask2_n]
        latitud = obs_tab["Lat"][mask2]
        latitud_p = obs_tab_p["Lat"][mask2_p]
        latitud_n =obs_tab_n["Lat"][mask2_n]
        longitud = obs_tab["Lon"][mask2]      
        longitud_p = obs_tab_p["Lon"][mask2_p]
        longitud_n =obs_tab_n["Lon"][mask2_n] 
        if datatype == "vTEC":
            dTEC =  np.gradient(obs_tab["Vtec"][mask2] - subs_TEC_int(cmn_time[mask2]))/np.gradient(cmn_time[mask2])
            dTEC_p = np.gradient(obs_tab_p["Vtec"][mask2_p]-subs_TEC_int(cmn_time_p[mask2_p]))/np.gradient(cmn_time_p[mask2_p])
            dTEC_n = np.gradient(obs_tab_n["Vtec"][mask2_n]-subs_TEC_int(cmn_time_n[mask2_n]))/np.gradient(cmn_time_n[mask2_n])
        elif datatype == "sTEC":
            dTEC =  np.gradient(obs_tab["Stec"][mask2]-subs_TEC_int(cmn_time[mask2]))/np.gradient(cmn_time[mask2]) 
            dTEC_p = np.gradient(obs_tab_p["Stec"][mask2_p]-subs_TEC_int(cmn_time[mask2_p]))/np.gradient(cmn_time_p[mask2_p]) 
            dTEC_n = np.gradient(obs_tab_n["Stec"][mask2_n]-subs_TEC_int(cmn_time[mask2_n]))/np.gradient(cmn_time_n[mask2_n]) 
    else:
        time=cmn_time
        time_p = cmn_time_p
        time_n = cmn_time_n
        latitud = obs_tab["Lat"]
        latitud_p = obs_tab_p["Lat"]
        latitud_n =obs_tab_n["Lat"]
        longitud = obs_tab["Lon"]
        longitud_p = obs_tab_p["Lon"]
        longitud_n =obs_tab_n["Lon"]
        if datatype == "vTEC":
            dTEC = np.gradient(obs_tab["Vtec"])/np.gradient(cmn_time)
            dTEC_p = np.gradient(obs_tab_p["Vtec"])/np.gradient(cmn_time_p)
            dTEC_n = np.gradient(obs_tab_n["Vtec"])/np.gradient(cmn_time_n)
        elif datatype == "sTEC":
            dTEC = np.gradient(obs_tab["Vtec"])/np.gradient(cmn_time)
            dTEC_p = np.gradient(obs_tab_p["Vtec"])/np.gradient(cmn_time_p)
            dTEC_n = np.gradient(obs_tab_n["Vtec"])/np.gradient(cmn_time_n)
    if log ==False:
        norm = MidpointNormalize(midpoint=0)
    else:
        norm = colors.SymLogNorm(linthresh=0.03, linscale=0.03, base=10)
    im1 = ax1.scatter(time, latitud, s=1, c=dTEC, cmap="viridis", alpha=0.6, norm=norm)
    im1_p = axp1.scatter(time_p, latitud_p, s=1, c=dTEC_p, cmap="viridis", alpha=0.6, norm=norm)
    im1_n = axn1.scatter(time_n, latitud_n, s=1, c=dTEC_n, cmap="viridis", alpha=0.6, norm=norm)
    im = ax.scatter(longitud-360, latitud, s=1, c=dTEC, cmap="viridis",alpha=0.6, norm=norm)
    im_p = axp.scatter(longitud_p-360, latitud_p, s=1, c=dTEC_p, cmap="viridis", alpha=0.6, norm=norm)
    im_n = axn.scatter(longitud_n-360, latitud_n, s=1, c=dTEC_n, cmap="viridis", alpha=0.6, norm=norm)



# Plot bolide trajectory

GLM16_file = open(directory+"/GLM/GLM-16-data.csv")
GLM17_file = open(directory+"/GLM/GLM-17-data.csv")

for i in range(10): # skip unneeded data
    GLM16_file.readline()
    GLM17_file.readline()

GLM16_data = GLM16_file.readlines()
GLM17_data = GLM17_file.readlines()
GLM16_table = Table.read(GLM16_data, format="ascii")
GLM17_table = Table.read(GLM17_data, format="ascii")

f1_longitude, f1_latitude = GLM16_table["longitude"], GLM16_table["latitude"]
f2_longitude, f2_latitude = GLM17_table["longitude"], GLM17_table["latitude"]


fit_coord1 = np.polyfit(f1_longitude, f1_latitude, 1)
fit_coord2 = np.polyfit(f2_longitude, f2_latitude, 1)


poly1 = np.poly1d(fit_coord1)
poly2 = np.poly1d(fit_coord2)
if f1_longitude[-1] > f1_longitude[0]:
    step1 = -20
else:
    step1 = 20

if f2_longitude[-1] > f2_longitude[0]:
    step2 = -20
else:
    step2 = 20

ax.plot([f1_longitude[0]+step1, f1_longitude[-1]], [poly1(f1_longitude[0]+step1), poly1(f1_longitude[-1])], "r--")
ax.plot([f2_longitude[0]+step2, f2_longitude[-1]], [poly2(f2_longitude[0]+step2), poly2(f2_longitude[-1])], "r--")

# Show the interval of time the event started

ax1.axvline(x=t0_m1, ls="--", c="k")
ax1.axvline(x=t0_m2, ls="--", c="k")
ax1.axvspan(min((t0_m1, t0_m2)), max((t0_m1, t0_m2)), alpha=0.5, color="red")

# add the second x-axis 

newlabel = [0, 5, 10, 15, 20, 25]
time_zone_dict = {"2019-05-23":-5, "2019-07-18":-5, "2019-08-10":-5, "2019-10-03":-5, "2019-10-09":-7, "2019-11-16":-6, "2019-11-17":-8, "2019-11-19":-7, "2019-11-26":-5, "2019-12-04":-7, "2019-12-15":-7, "2019-12-29":-8, "2020-01-03":-8, "2020-01-06":-7, "2020-01-15":-6, "2020-02-12":-6, "2020-03-03":-6, "2020-03-31":-7, "2020-04-08":-5, "2020-04-18":-6, "2020-04-20":-5, "2020-04-25":-7, "2020-04-28":-6, "2020-05-08":-5, "2020-07-15":-6, "2020-08-07":-6, "2020-09-13":-7, "2020-09-30":-7, "2020-11-16":-6, "2020-11-17":-6, "2020-12-19":-6, "2020-12-23":-7, "2020-12-29":-6, "2021-03-31":-6}

local_time = np.array(newlabel) + time_zone_dict[date]
for i in range(len(local_time)):
    if local_time[i] < 0.:
        local_time[i] = local_time[i] + 24.0
ax2 = ax1.twiny()
ax2.set_xticks(newlabel)
ax2.set_xticklabels(local_time)
ax2.set_xlim(ax1.get_xlim())

axp2 = axp1.twiny()
axp2.set_xticks(newlabel)
axp2.set_xticklabels(local_time)
axp2.set_xlabel("Local Time (hours)")
axp2.set_xlim(axp1.get_xlim())

axn2 = axn1.twiny()
axn2.set_xticks(newlabel)
axn2.set_xticklabels(local_time)
axn2.set_xlim(axn1.get_xlim())

# Daytime shaded in light yellow and night time in blue

# local sunrise and sunset dictionaries 

sunrise_p = {"2019-05-23":6+57./60, "2019-07-18":7+14./60, "2019-08-10":7+25./60, "2019-10-03":7+26/60., "2019-10-09":7+16./60, "2019-11-16": 7+18./60, "2019-11-17": 6+19/60., "2019-11-19": 7+ 6./60, "2019-11-26": 6+33/60., "2019-12-04": 7+17./60, "2019-12-15": 7+0./60, "2019-12-29": 6+46/60., "2020-01-03": 6+47./60, "2020-01-06": 7+ 7./60, "2020-01-15": 7+1./60, "2020-02-12": 6+41./60, "2020-03-03": 7+16./60, "2020-03-31": 6+16/60., "2020-04-08": 7+ 4./60, "2020-04-18": 6+37./60, "2020-04-20": 7+3./60, "2020-04-25": 5+44./60, "2020-04-28": 6+50./60, "2020-05-08": 6+42./60, "2020-07-15":6.5, "2020-08-07":6.5, "2020-09-13": 7+14./60, "2020-09-30":7+13./60, "2020-11-16": 6+52./60, "2020-11-17": 7+5./60, "2020-12-19":7+20./60, "2020-12-23": 7+ 1./60, "2020-12-29": 7+19/60., "2021-03-31": 6+ 8./60}


sunset_p = {"2019-05-23":20+24./60, "2019-07-18":20+45./60, "2019-08-10":20+23./60, "2019-10-03":19+17/60., "2019-10-09":19, "2019-11-16":17+52./60, "2019-11-17":16+45/60., "2019-11-19":18+14./60, "2019-11-26":17+19/60., "2019-12-04":17.5, "2019-12-15":20+6./60, "2019-12-29":16+49/60., "2020-01-03":16+53./60, "2020-01-06":17+15./60, "2020-01-15":18+5./60, "2020-02-12":18+10./60, "2020-03-03":19+2./60, "2020-03-31":18+40/60., "2020-04-08":19+42./60, "2020-04-18":19.5, "2020-04-20":20+2./60, "2020-04-25":18+58./60, "2020-04-28":19+47./60, "2020-05-08":19+33./60, "2020-07-15":20, "2020-08-07":19+49./60, "2020-09-13":19+35./60, "2020-09-30":19+8./60, "2020-11-16":17+59./60, "2020-11-17":18+4./60, "2020-12-19":18+5./60, "2020-12-23":17+38./60, "2020-12-29":18+21/60., "2021-03-31":18+23./60}

sunrise = {"2019-05-23":6+56./60, "2019-07-18":7+14./60, "2019-08-10":7+26./60, "2019-10-03":7+27/60., "2019-10-09":7+17./60, "2019-11-16": 7+19./60, "2019-11-17": 6+20/60., "2019-11-19": 7+ 6./60, "2019-11-26": 6+34/60., "2019-12-04": 7+18./60, "2019-12-15": 7+1./60, "2019-12-29": 6+46/60., "2020-01-03": 6+47./60, "2020-01-06": 7+ 7./60, "2020-01-15": 7+1./60, "2020-02-12": 6+41./60, "2020-03-03": 7+15./60, "2020-03-31": 6+15/60., "2020-04-08": 7+ 3./60, "2020-04-18": 6+36./60, "2020-04-20": 7+2./60, "2020-04-25": 5+43./60, "2020-04-28": 6+49./60, "2020-05-08": 6+42./60, "2020-07-15":6.5, "2020-08-07":6.5, "2020-09-13": 7+14./60, "2020-09-30":7+13./60, "2020-11-16": 6+53./60, "2020-11-17": 7+3./60, "2020-12-19":7+19./60, "2020-12-23": 7+ 2./60, "2020-12-29": 7+20/60., "2021-03-31": 6+ 7./60}

sunset = {"2019-05-23":20+25./60, "2019-07-18":20+45./60, "2019-08-10":20+22./60, "2019-10-03":19+16/60., "2019-10-09":18+59./60, "2019-11-16":17+52./60, "2019-11-17":16+45/60., "2019-11-19":18+14./60, "2019-11-26":17+19/60., "2019-12-04":17.5, "2019-12-15":20+5./60, "2019-12-29":16+50/60., "2020-01-03":16+53./60, "2020-01-06":17+15./60, "2020-01-15":18+5./60, "2020-02-12":18+10./60, "2020-03-03":19+2./60, "2020-03-31":18+40/60., "2020-04-08":19+43./60, "2020-04-18":19.5, "2020-04-20":20+3./60, "2020-04-25":18+59./60, "2020-04-28":19+48./60, "2020-05-08":19+34./60, "2020-07-15":20, "2020-08-07":19+49./60, "2020-09-13":19+34./60, "2020-09-30":19+7./60, "2020-11-16":17+59./60, "2020-11-17":18+4./60, "2020-12-19":18+6./60, "2020-12-23":17+39./60, "2020-12-29":18+22/60., "2021-03-31":18+24./60}

sunrise_n= {"2019-05-23":6+56./60, "2019-07-18":7+15./60, "2019-08-10":7+26./60, "2019-10-03":7+27/60., "2019-10-09":7+17./60, "2019-11-16": 7+20./60, "2019-11-17": 6+21/60., "2019-11-19": 7+ 6./60, "2019-11-26": 6+35/60., "2019-12-04": 7+19./60, "2019-12-15": 7+1./60, "2019-12-29": 6+46/60., "2020-01-03": 6+48./60, "2020-01-06": 7+ 7./60, "2020-01-15": 7+8./60, "2020-02-12": 6+40./60, "2020-03-03": 7+14./60, "2020-03-31": 6+13/60., "2020-04-08": 7+ 1./60, "2020-04-18": 6+35./60, "2020-04-20": 7+1./60, "2020-04-25": 5+42./60, "2020-04-28": 6+49./60, "2020-05-08": 6+41./60, "2020-07-15":6.5, "2020-08-07":6.5, "2020-09-13": 7+15./60, "2020-09-30":7+14./60, "2020-11-16": 6+53./60, "2020-11-17": 7+6./60, "2020-12-19":7+20./60, "2020-12-23": 7+ 2./60, "2020-12-29": 7+20/60., "2021-03-31": 6+ 6./60}

sunset_n = {"2019-05-23":20+25./60, "2019-07-18":20+44./60, "2019-08-10":20+21./60, "2019-10-03":19+15/60., "2019-10-09":18+58./60, "2019-11-16":17+52./60, "2019-11-17":16+44/60., "2019-11-19":18+13./60, "2019-11-26":17+19/60., "2019-12-04":17.5, "2019-12-15":20+4./60, "2019-12-29":16+51/60., "2020-01-03":16+54./60, "2020-01-06":17+16./60, "2020-01-15":18+5./60, "2020-02-12":18+10./60, "2020-03-03":19+3./60, "2020-03-31":18+41/60., "2020-04-08":19+44./60, "2020-04-18":19.5, "2020-04-20":20+3./60, "2020-04-25":19, "2020-04-28":19+48./60, "2020-05-08":19+34./60, "2020-07-15":20, "2020-08-07":19+48./60, "2020-09-13":19+33./60, "2020-09-30":19+6./60, "2020-11-16":17+59./60, "2020-11-17":18+4./60, "2020-12-19":18+7./60, "2020-12-23":17+39./60, "2020-12-29":18+22/60., "2021-03-31":18+24./60}

sunrise_p_UT = sunrise_p[date] - time_zone_dict[date]
sunset_p_UT = sunset_p[date] - time_zone_dict[date]
sunrise_UT = sunrise[date] - time_zone_dict[date]
sunset_UT = sunset[date] - time_zone_dict[date]
sunrise_n_UT = sunrise_n[date] - time_zone_dict[date]
sunset_n_UT = sunset_n[date] - time_zone_dict[date]


axp1.axvspan(0, sunrise_p_UT, alpha=0.1, color="cyan")
axp1.axvspan(sunrise_p_UT, min(sunset_p_UT, 24.0), alpha=0.1, color="yellow")
if sunset_p_UT < 24.0:
    axp1.axvspan(sunset_p_UT, 24.0, alpha=0.1, color="cyan")
ax1.axvspan(max(0, sunset_p_UT-24.0), sunrise_UT, alpha=0.1, color="cyan")
if sunset_p_UT-24 > 0:
    ax1.axvspan(0, sunset_p_UT-24, alpha=0.1, color="yellow")
ax1.axvspan(sunrise_UT, min(sunset_UT, 24.0), alpha=0.1, color="yellow")
if sunset_UT < 24.0:
    ax1.axvspan(sunset_UT, 24.0, alpha=0.1, color="cyan")
axn1.axvspan(max(0, sunset_UT-24.0), sunrise_n_UT, alpha=0.1, color="cyan")
if sunset_UT - 24.0 >0:
    axn1.axvspan(0, sunset_UT-24, alpha=0.1, color="yellow")
axn1.axvspan(sunrise_n_UT, 24.0, alpha=0.1, color="yellow")

# Plot settings


label = "Rate of {} for {} stations".format(datatype, len(rinex_files))
if log ==True:
    cbar = fig.colorbar(im, ax=ax, ticks=[-1e1, -1, -1e-1, 1e-1, 1, 1e1])
    cbar.ax.minorticks_on()
    cbar_p = fig.colorbar(im_p, ax=axp, ticks=[-1e1, -1, -1e-1, 1e-1, 1, 1e1])
    cbar_p.ax.minorticks_on()
    cbar_n = fig.colorbar(im_n, ax=axn, ticks=[-1e1, -1, -1e-1, 1e-1, 1, 1e1])
    cbar_n.ax.minorticks_on()
    cbar1 = fig.colorbar(im1, ax=ax1, ticks=[-1e1, -1, -1e-1, 1e-1, 1, 1e1])
    cbar1.ax.minorticks_on()
    cbar1_p = fig.colorbar(im1_p, ax=axp1, ticks=[-1e1, -1, -1e-1, 1e-1, 1, 1e1])
    cbar1_p.ax.minorticks_on()
    cbar1_n = fig.colorbar(im1_n, ax=axn1, ticks=[-1e1, -1, -1e-1, 1e-1, 1, 1e1])
    cbar1_n.ax.minorticks_on()
else:
    cbar = fig.colorbar(im, ax=ax)
    cbar_p = fig.colorbar(im_p, ax=axp)
    cbar_n = fig.colorbar(im_n, ax=axn)
    cbar1 = fig.colorbar(im1, ax=ax1)
    cbar1_p = fig.colorbar(im1_p, ax=axp1)
    cbar1_n = fig.colorbar(im1_n, ax=axn1)

cbar.set_label("Rate of {} (TECU/s)".format(datatype))
cbar_p.set_label("Rate of {} (TECU/s)".format(datatype))
cbar_n.set_label("Rate of {} (TECU/s)".format(datatype))
cbar1.set_label("Rate of {} (TECU/s)".format(datatype))
cbar1_p.set_label("Rate of {} (TECU/s)".format(datatype))
cbar1_n.set_label("Rate of {} (TECU/s)".format(datatype))
out_dir = "./rTEC-maps/"
axn.set_xlabel("Longitude (deg)")
ax.set_ylabel("Latitude (deg)")
axp.set_ylabel("Latitude (deg)")
axn.set_ylabel("Latitude (deg)")
axn1.set_xlabel("Universal Time (hours)")
plt.suptitle(date+"Rate of {} map".format(datatype))
ax1.set_ylabel("Latitude (deg)")
axp1.set_ylabel("Latitude (deg)")
axn1.set_ylabel("Latitude (deg)")
axp.title.set_text(label + ". Previous day")
axp1.title.set_text(label)
ax.title.set_text(label + ". Event date")
#ax1.title.set_text(label)
axn.title.set_text(label+". Next day")
#axn1.title.set_text(label)
fig.set_size_inches(22, 18)
#fig.tight_layout()

if substract == True:
    if log ==True:
        plt.savefig(out_dir+date+"-Rate of {}_logmap_minus_background.".format(datatype)+formato)
    else:
        plt.savefig(out_dir+date+"-Rate of {}_map_minus_background.".format(datatype)+formato)
else:
    if log==True:
        plt.savefig(out_dir+date+"-Rate of {}_logmap.".format(datatype)+formato)
    else:
        plt.savefig(out_dir+date+"-Rate of {}_map.".format(datatype)+formato)

#+END_SRC

#+NAME delta_vTEC
#+BEGIN_SRC python :eval no :tangle ./delta_vTEC.py

# To check if vTEC is strongly perturbed (as we may expect from a meteor entrance), we may calculate the parameter
# \delta, defined as:

#             (vTEC_max - <vTEC>)
#   \delta = ---------------------- (Martinez et al. 2014)
#                    <vTEC>
# If \delta >~4 is an indication that the vTEC is strongly disturbed. But since the observed meteors in the GLM sample are small ( <~1m ), we will be less strict with this criteria
# and set |\delta| >~ 2 and compute this parameter instead of vTEC itself

# For this we will do a variant of the vTEC_maps program since we will compute \delta for each vTEC measurement. <vTEC> will be obtained from the average TEC in the .Std file.

import seaborn as sns
import numpy as np
import pandas as pd
import shapefile as shp
import matplotlib.pyplot as plt
from plotfullmap import plot_map
import argparse
from astropy.table import Table
import glob
import matplotlib.cm as cm
import matplotlib.colors as colors
from scipy.interpolate import interp1d
from midpoint import MidpointNormalize



parser = argparse.ArgumentParser(
    description=""" Choose a file to work""")


parser.add_argument('--date', type=str, default='2000-01-01',
			       help='Choose date. Format: yyyy-mm-dd')

parser.add_argument("--formato", type=str, default="pdf", choices=("pdf", "png", "jpg"), 
                                help="Choose output format")

parser.add_argument("--log", action="store_true", help="Use logarithmic scale for vTEC")

parser.add_argument("--substract", action="store_true", help="substract the median of 27 previous days")
parser.add_argument("--data", type=str, default="vTEC", choices=("vTEC", "sTEC"))

cmd_args = parser.parse_args()
date = cmd_args.date
formato = cmd_args.formato
log = cmd_args.log
substract = cmd_args.substract
datatype = cmd_args.data
directory = "./data/"+date
p_directory = directory + "/previous/"
n_directory = directory+ "/next/"

# set figure style
sns.set_style("whitegrid") 


# Load RINEX capabilities

rinex_files = glob.glob(directory+"/*.Cmn")
std_files = glob.glob(directory+"/*.Std")
load_dirs = [open(rinex_files[i], "r") for i in range(len(rinex_files))]
load_std = [Table.read(std_files[i], format="ascii") for i in range(len(std_files))]


rinex_p = glob.glob(p_directory+"*.Cmn")
std_p = glob.glob(p_directory+"*.Std")
rinex_n = glob.glob(n_directory+"*.Cmn")
std_n = glob.glob(n_directory+"*.Std")

load_dir_p = [open(rinex_p[i], "r") for i in range(len(rinex_p))]
load_std_p = [Table.read(std_p[i], format="ascii") for i in range(len(std_p))]
load_dir_n = [open(rinex_n[i], "r") for i in range(len(rinex_n))]
load_std_n = [Table.read(std_n[i], format="ascii") for i in range(len(std_n))]

if substract ==True:
    load_back = glob.glob(directory+"/*.tab")
    stations_names = []
    stations_files = []
    for l in load_back:
        home, dfolder, fecha, tabfile = l.split("/")
        s_name = tabfile.split("-")[0]
        stations_names.append(s_name)
        stations_files.append(tabfile)
    stations_dict = dict(zip(stations_names, stations_files))

# Plot vTEC map
fig = plt.figure()
ax = fig.add_subplot(3, 2, 3, adjustable="box", aspect="equal")
ax1 = fig.add_subplot(3, 2, 4, adjustable="box")
axp = fig.add_subplot(3, 2, 1, adjustable="box", aspect="equal")
axp1 = fig.add_subplot(3, 2, 2, adjustable="box")
axn = fig.add_subplot(3, 2, 5, adjustable="box", aspect="equal")
axn1 = fig.add_subplot(3, 2, 6, adjustable="box")


# Load and plot event position and start time

load_meteor_pos = Table.read("meteors_database.tab", format="ascii")
meteor_mask = load_meteor_pos["Fecha"] == date
ax.plot(load_meteor_pos["Longitud"][meteor_mask], load_meteor_pos["Latitud"][meteor_mask], "mo")

t0_meteor_1 = load_meteor_pos["T_0 (GLM-16)"][meteor_mask]
t0_meteor_2 = load_meteor_pos["T_0 (GLM-17)"][meteor_mask]
# convert start time from string to float (in hours)
t0_m1_h, t0_m1_m, t0_m1_s = t0_meteor_1[0].split(":")
t0_m2_h, t0_m2_m, t0_m2_s = t0_meteor_2[0].split(":")

t0_m1 = float(t0_m1_h) + float(t0_m1_m)/60. + float(t0_m1_s)/3600.
t0_m2 = float(t0_m2_h) + float(t0_m2_m)/60. + float(t0_m2_s)/3600.

# Load and plot RINEX data

for f, g, fp, gp, fn, gn in zip(load_dirs, load_std, load_dir_p, load_std_p, load_dir_n, load_std_n):
    header = f.readline()
    header_p = fp.readline()
    header_n = fn.readline()
    h1, h2 = header.split(",")
    station = h2.split("\\")[-1][0:4]
    blank = f.readline()
    blank = fp.readline()
    blank = fn.readline()
    s_coords = f.readline()
    s_coords_p = fp.readline()
    s_coords_n = fn.readline()
    s_latitude, s_longitude, s_altitude = s_coords.split()
    blank = f.readline()
    blank = fp.readline()
    blank = fn.readline()
    data  = f.readlines()
    data_p = fp.readlines()
    data_n = fn.readlines()
    obs_tab = Table.read(data, format="ascii")
    obs_tab_p = Table.read(data_p, format="ascii")
    obs_tab_n = Table.read(data_n, format="ascii")
    std_time = g["col1"]
    std_time_p = gp["col1"]
    std_time_n = gn["col1"]
    std_TEC = g["col2"]
    std_TEC_p = gp["col2"]
    std_TEC_n = gn["col2"]
    for i in range(len(obs_tab["Vtec"])): # Replace "-" into NaN since there is no data
        if obs_tab["Vtec"][i] == "-":
            obs_tab["Vtec"][i] = np.nan
    for i in range(len(obs_tab_p["Vtec"])):
        if obs_tab_p["Vtec"][i] == "-":
            obs_tab_p["Vtec"][i] = np.nan
    for i in range(len(obs_tab_n["Vtec"])):
        if obs_tab_n["Vtec"][i] == "-":
            obs_tab_n["Vtec"][i] = np.nan

    for i in range(len(std_TEC)):
        if std_TEC[i] == "-":
            std_TEC[i]=np.nan
    for i in range(len(std_TEC_p)):
        if std_TEC_p[i] == "-":
            std_TEC_p[i]=np.nan
    for i in range(len(std_TEC_n)):
        if std_TEC_n[i] == "-":
            std_TEC_n[i]=np.nan

    mean_TEC_int = interp1d(std_time, std_TEC)
    mean_TEC_int_p = interp1d(std_time_p, std_TEC_p)
    mean_TEC_int_n = interp1d(std_time_n, std_TEC_p)
    cmn_time = obs_tab["Time"]
    cmn_time_p = obs_tab_p["Time"]
    cmn_time_n = obs_tab_n["Time"]
    mask = cmn_time < 0
    mask_p = cmn_time_p < 0
    mask_n = cmn_time_n < 0
    cmn_time[mask] = cmn_time[mask] + 24.
    cmn_time_p[mask_p] = cmn_time_p[mask_p] + 24.0
    cmn_time_n[mask_n] = cmn_time_n[mask_n] + 24.0
    mask2 = cmn_time < max(std_time)
    mask2_p = cmn_time_p < max(std_time_p)
    mask2_n = cmn_time_n < max(std_time_n)
    if substract==True:
        subs_tab = Table.read(directory+"/"+stations_dict[station], format="ascii")
        subs_TEC = subs_tab["Mean vTEC"]
        for i in range(len(subs_TEC)):
            if subs_TEC[i] == "-":
                subs_TEC[i] = np.nan
        subs_TEC_int = interp1d(std_time, subs_TEC) # Maybe substract the mean TEC AND the background TEC is redundant
        if datatype == "vTEC":
            dTEC =  (obs_tab["Vtec"][mask2] - subs_TEC_int(cmn_time[mask2]))/subs_TEC_int(cmn_time[mask2])
            dTEC_p = (obs_tab_p["Vtec"][mask2_p] -subs_TEC_int(cmn_time_p[mask2_p]))/subs_TEC_int(cmn_time_p[mask2_p])
            dTEC_n = (obs_tab_n["Vtec"][mask2_n] -subs_TEC_int(cmn_time_n[mask2_n]))/subs_TEC_int(cmn_time_n[mask2_n])
        elif datatype == "sTEC":
            dTEC =  (obs_tab["Stec"][mask2] - subs_TEC_int(cmn_time[mask2]))/subs_TEC_int(cmn_time[mask2])
            dTEC_p = (obs_tab_p["Stec"][mask2_p] -subs_TEC_int(cmn_time_p[mask2_p]))/subs_TEC_int(cmn_time_p[mask2_p])
            dTEC_n = obs_tab_n["Stec"][mask2_n] -subs_TEC_int(cmn_time_n[mask2_n])/subs_TEC_int(cmn_time_n[mask2_n])

    else:
        if datatype == "vTEC":
            dTEC = (obs_tab["Vtec"][mask2] - mean_TEC_int(cmn_time[mask2]))/mean_TEC_int(cmn_time[mask2])
            dTEC_p = (obs_tab_p["Vtec"][mask2_p] - mean_TEC_int_p(cmn_time_p[mask2_p]))/mean_TEC_int_p(cmn_time_p[mask2_p])
            dTEC_n = (obs_tab_n["Vtec"][mask2_n] - mean_TEC_int_n(cmn_time_n[mask2_n]))/mean_TEC_int_n(cmn_time_n[mask2_n])
        elif datatype == "sTEC":
            dTEC = (obs_tab["Stec"][mask2] - mean_TEC_int(cmn_time[mask2]))/mean_TEC_int(cmn_time[mask2])
            dTEC_p = (obs_tab_p["Stec"][mask2_p] - mean_TEC_int_p(cmn_time_p[mask2_p]))/mean_TEC_int_p(cmn_time_p[mask2_p])
            dTEC_n = (obs_tab_n["Stec"][mask2_n] - mean_TEC_int_n(cmn_time_n[mask2_n]))/mean_TEC_int_n(cmn_time_n[mask2_n])
    if log ==True: 
        norm = colors.SymLogNorm(linthresh=0.03, linscale=0.03, base=10)
    else: 
        norm = MidpointNormalize(midpoint=0)
    im1=ax1.scatter(cmn_time[mask2], obs_tab["Lat"][mask2], s=1, c=dTEC, cmap="viridis", alpha=0.6, norm=norm)
    im1_p = axp1.scatter(cmn_time_p[mask2_p], obs_tab_p["Lat"][mask2_p], s=1, c=dTEC_p, cmap="viridis", alpha=0.6, norm=norm)
    im1_n = axn1.scatter(cmn_time_n[mask2_n], obs_tab_n["Lat"][mask2_n], s=1, c=dTEC_n, cmap="viridis", alpha=0.6, norm=norm)
    im=ax.scatter(obs_tab["Lon"][mask2]-360, obs_tab["Lat"][mask2], s=1, c=dTEC, cmap="viridis",alpha=0.6, norm=norm)
    im_p = axp.scatter(obs_tab_p["Lon"][mask2_p]-360, obs_tab_p["Lat"][mask2_p], s=1, c=dTEC_p, cmap="viridis", alpha=0.6, norm=norm)
    im_n = axn.scatter(obs_tab_n["Lon"][mask2_n]-360, obs_tab_n["Lat"][mask2_n], s=1, c=dTEC_n, cmap="viridis", alpha=0.6, norm=norm)

# Plot bolide trajectory

GLM16_file = open(directory+"/GLM/GLM-16-data.csv")
GLM17_file = open(directory+"/GLM/GLM-17-data.csv")

for i in range(10): # skip unneeded data
    GLM16_file.readline()
    GLM17_file.readline()

GLM16_data = GLM16_file.readlines()
GLM17_data = GLM17_file.readlines()
GLM16_table = Table.read(GLM16_data, format="ascii")
GLM17_table = Table.read(GLM17_data, format="ascii")

f1_longitude, f1_latitude = GLM16_table["longitude"], GLM16_table["latitude"]
f2_longitude, f2_latitude = GLM17_table["longitude"], GLM17_table["latitude"]


fit_coord1 = np.polyfit(f1_longitude, f1_latitude, 1)
fit_coord2 = np.polyfit(f2_longitude, f2_latitude, 1)


poly1 = np.poly1d(fit_coord1)
poly2 = np.poly1d(fit_coord2)
if f1_longitude[-1] > f1_longitude[0]:
    step1 = -20
else:
    step1 = 20

if f2_longitude[-1] > f2_longitude[0]:
    step2 = -20
else:
    step2 = 20
ax.plot([f1_longitude[0]+step1, f1_longitude[-1]], [poly1(f1_longitude[0]+step1), poly1(f1_longitude[-1])], "r--")
ax.plot([f2_longitude[0]+step2, f2_longitude[-1]], [poly2(f2_longitude[0]+step2), poly2(f2_longitude[-1])], "r--")

# Show the interval of time the event started

ax1.axvline(x=t0_m1, ls="--", c="k")
ax1.axvline(x=t0_m2, ls="--", c="k")
ax1.axvspan(min((t0_m1, t0_m2)), max((t0_m1, t0_m2)), alpha=0.5, color="red")

# add the second x-axis 

newlabel = [0, 5, 10, 15, 20, 25]
time_zone_dict = {"2019-05-23":-5, "2019-07-18":-5, "2019-08-10":-5, "2019-10-03":-5, "2019-10-09":-7, "2019-11-16":-6, "2019-11-17":-8, "2019-11-19":-7, "2019-11-26":-5, "2019-12-04":-7, "2019-12-15":-7, "2019-12-29":-8, "2020-01-03":-8, "2020-01-06":-7, "2020-01-15":-6, "2020-02-12":-6, "2020-03-03":-6, "2020-03-31":-7, "2020-04-08":-5, "2020-04-18":-6, "2020-04-20":-5, "2020-04-25":-7, "2020-04-28":-6, "2020-05-08":-5, "2020-07-15":-6, "2020-08-07":-6, "2020-09-13":-7, "2020-09-30":-7, "2020-11-16":-6, "2020-11-17":-6, "2020-12-19":-6, "2020-12-23":-7, "2020-12-29":-6, "2021-03-31":-6}

local_time = np.array(newlabel) + time_zone_dict[date]
for i in range(len(local_time)):
    if local_time[i] < 0.:
        local_time[i] = local_time[i] + 24.0
ax2 = ax1.twiny()
ax2.set_xticks(newlabel)
ax2.set_xticklabels(local_time)
ax2.set_xlim(ax1.get_xlim())

axp2 = axp1.twiny()
axp2.set_xticks(newlabel)
axp2.set_xticklabels(local_time)
axp2.set_xlabel("Local Time (hours)")
axp2.set_xlim(axp1.get_xlim())

axn2 = axn1.twiny()
axn2.set_xticks(newlabel)
axn2.set_xticklabels(local_time)
axn2.set_xlim(axn1.get_xlim())

# Daytime shaded in light yellow and night time in blue

# local sunrise and sunset dictionaries 

sunrise_p = {"2019-05-23":6+57./60, "2019-07-18":7+14./60, "2019-08-10":7+25./60, "2019-10-03":7+26/60., "2019-10-09":7+16./60, "2019-11-16": 7+18./60, "2019-11-17": 6+19/60., "2019-11-19": 7+ 6./60, "2019-11-26": 6+33/60., "2019-12-04": 7+17./60, "2019-12-15": 7+0./60, "2019-12-29": 6+46/60., "2020-01-03": 6+47./60, "2020-01-06": 7+ 7./60, "2020-01-15": 7+1./60, "2020-02-12": 6+41./60, "2020-03-03": 7+16./60, "2020-03-31": 6+16/60., "2020-04-08": 7+ 4./60, "2020-04-18": 6+37./60, "2020-04-20": 7+3./60, "2020-04-25": 5+44./60, "2020-04-28": 6+50./60, "2020-05-08": 6+42./60, "2020-07-15":6.5, "2020-08-07":6.5, "2020-09-13": 7+14./60, "2020-09-30":7+13./60, "2020-11-16": 6+52./60, "2020-11-17": 7+5./60, "2020-12-19":7+20./60, "2020-12-23": 7+ 1./60, "2020-12-29": 7+19/60., "2021-03-31": 6+ 8./60}


sunset_p = {"2019-05-23":20+24./60, "2019-07-18":20+45./60, "2019-08-10":20+23./60, "2019-10-03":19+17/60., "2019-10-09":19, "2019-11-16":17+52./60, "2019-11-17":16+45/60., "2019-11-19":18+14./60, "2019-11-26":17+19/60., "2019-12-04":17.5, "2019-12-15":20+6./60, "2019-12-29":16+49/60., "2020-01-03":16+53./60, "2020-01-06":17+15./60, "2020-01-15":18+5./60, "2020-02-12":18+10./60, "2020-03-03":19+2./60, "2020-03-31":18+40/60., "2020-04-08":19+42./60, "2020-04-18":19.5, "2020-04-20":20+2./60, "2020-04-25":18+58./60, "2020-04-28":19+47./60, "2020-05-08":19+33./60, "2020-07-15":20, "2020-08-07":19+49./60, "2020-09-13":19+35./60, "2020-09-30":19+8./60, "2020-11-16":17+59./60, "2020-11-17":18+4./60, "2020-12-19":18+5./60, "2020-12-23":17+38./60, "2020-12-29":18+21/60., "2021-03-31":18+23./60}

sunrise = {"2019-05-23":6+56./60, "2019-07-18":7+14./60, "2019-08-10":7+26./60, "2019-10-03":7+27/60., "2019-10-09":7+17./60, "2019-11-16": 7+19./60, "2019-11-17": 6+20/60., "2019-11-19": 7+ 6./60, "2019-11-26": 6+34/60., "2019-12-04": 7+18./60, "2019-12-15": 7+1./60, "2019-12-29": 6+46/60., "2020-01-03": 6+47./60, "2020-01-06": 7+ 7./60, "2020-01-15": 7+1./60, "2020-02-12": 6+41./60, "2020-03-03": 7+15./60, "2020-03-31": 6+15/60., "2020-04-08": 7+ 3./60, "2020-04-18": 6+36./60, "2020-04-20": 7+2./60, "2020-04-25": 5+43./60, "2020-04-28": 6+49./60, "2020-05-08": 6+42./60, "2020-07-15":6.5, "2020-08-07":6.5, "2020-09-13": 7+14./60, "2020-09-30":7+13./60, "2020-11-16": 6+53./60, "2020-11-17": 7+3./60, "2020-12-19":7+19./60, "2020-12-23": 7+ 2./60, "2020-12-29": 7+20/60., "2021-03-31": 6+ 7./60}

sunset = {"2019-05-23":20+25./60, "2019-07-18":20+45./60, "2019-08-10":20+22./60, "2019-10-03":19+16/60., "2019-10-09":18+59./60, "2019-11-16":17+52./60, "2019-11-17":16+45/60., "2019-11-19":18+14./60, "2019-11-26":17+19/60., "2019-12-04":17.5, "2019-12-15":20+5./60, "2019-12-29":16+50/60., "2020-01-03":16+53./60, "2020-01-06":17+15./60, "2020-01-15":18+5./60, "2020-02-12":18+10./60, "2020-03-03":19+2./60, "2020-03-31":18+40/60., "2020-04-08":19+43./60, "2020-04-18":19.5, "2020-04-20":20+3./60, "2020-04-25":18+59./60, "2020-04-28":19+48./60, "2020-05-08":19+34./60, "2020-07-15":20, "2020-08-07":19+49./60, "2020-09-13":19+34./60, "2020-09-30":19+7./60, "2020-11-16":17+59./60, "2020-11-17":18+4./60, "2020-12-19":18+6./60, "2020-12-23":17+39./60, "2020-12-29":18+22/60., "2021-03-31":18+24./60}

sunrise_n= {"2019-05-23":6+56./60, "2019-07-18":7+15./60, "2019-08-10":7+26./60, "2019-10-03":7+27/60., "2019-10-09":7+17./60, "2019-11-16": 7+20./60, "2019-11-17": 6+21/60., "2019-11-19": 7+ 6./60, "2019-11-26": 6+35/60., "2019-12-04": 7+19./60, "2019-12-15": 7+1./60, "2019-12-29": 6+46/60., "2020-01-03": 6+48./60, "2020-01-06": 7+ 7./60, "2020-01-15": 7+8./60, "2020-02-12": 6+40./60, "2020-03-03": 7+14./60, "2020-03-31": 6+13/60., "2020-04-08": 7+ 1./60, "2020-04-18": 6+35./60, "2020-04-20": 7+1./60, "2020-04-25": 5+42./60, "2020-04-28": 6+49./60, "2020-05-08": 6+41./60, "2020-07-15":6.5, "2020-08-07":6.5, "2020-09-13": 7+15./60, "2020-09-30":7+14./60, "2020-11-16": 6+53./60, "2020-11-17": 7+6./60, "2020-12-19":7+20./60, "2020-12-23": 7+ 2./60, "2020-12-29": 7+20/60., "2021-03-31": 6+ 6./60}

sunset_n = {"2019-05-23":20+25./60, "2019-07-18":20+44./60, "2019-08-10":20+21./60, "2019-10-03":19+15/60., "2019-10-09":18+58./60, "2019-11-16":17+52./60, "2019-11-17":16+44/60., "2019-11-19":18+13./60, "2019-11-26":17+19/60., "2019-12-04":17.5, "2019-12-15":20+4./60, "2019-12-29":16+51/60., "2020-01-03":16+54./60, "2020-01-06":17+16./60, "2020-01-15":18+5./60, "2020-02-12":18+10./60, "2020-03-03":19+3./60, "2020-03-31":18+41/60., "2020-04-08":19+44./60, "2020-04-18":19.5, "2020-04-20":20+3./60, "2020-04-25":19, "2020-04-28":19+48./60, "2020-05-08":19+34./60, "2020-07-15":20, "2020-08-07":19+48./60, "2020-09-13":19+33./60, "2020-09-30":19+6./60, "2020-11-16":17+59./60, "2020-11-17":18+4./60, "2020-12-19":18+7./60, "2020-12-23":17+39./60, "2020-12-29":18+22/60., "2021-03-31":18+24./60}

sunrise_p_UT = sunrise_p[date] - time_zone_dict[date]
sunset_p_UT = sunset_p[date] - time_zone_dict[date]
sunrise_UT = sunrise[date] - time_zone_dict[date]
sunset_UT = sunset[date] - time_zone_dict[date]
sunrise_n_UT = sunrise_n[date] - time_zone_dict[date]
sunset_n_UT = sunset_n[date] - time_zone_dict[date]


axp1.axvspan(0, sunrise_p_UT, alpha=0.1, color="cyan")
axp1.axvspan(sunrise_p_UT, min(sunset_p_UT, 24.0), alpha=0.1, color="yellow")
if sunset_p_UT < 24.0:
    axp1.axvspan(sunset_p_UT, 24.0, alpha=0.1, color="cyan")
ax1.axvspan(max(0, sunset_p_UT-24.0), sunrise_UT, alpha=0.1, color="cyan")
if sunset_p_UT-24 > 0:
    ax1.axvspan(0, sunset_p_UT-24, alpha=0.1, color="yellow")
ax1.axvspan(sunrise_UT, min(sunset_UT, 24.0), alpha=0.1, color="yellow")
if sunset_UT < 24.0:
    ax1.axvspan(sunset_UT, 24.0, alpha=0.1, color="cyan")
axn1.axvspan(max(0, sunset_UT-24.0), sunrise_n_UT, alpha=0.1, color="cyan")
if sunset_UT - 24.0 >0:
    axn1.axvspan(0, sunset_UT-24, alpha=0.1, color="yellow")
axn1.axvspan(sunrise_n_UT, 24.0, alpha=0.1, color="yellow")

# Plot settings

label = r"$\delta$ parameter for {} for {} stations".format(datatype, len(rinex_files))
if log ==True:
    cbar = fig.colorbar(im, ax=ax, ticks=[-1, -1e-1, -1e-2, 1e-2, 1e-1, 1])
    cbar.ax.minorticks_on()
    cbar_p = fig.colorbar(im_p, ax=axp, ticks=[-1, -1e-1, -1e-2, 1e-2, 1e-1, 1])
    cbar_p.ax.minorticks_on()
    cbar_n = fig.colorbar(im_n, ax=axn, ticks=[-1, -1e-1, -1e-2, 1e-2, 1e-1, 1])
    cbar_n.ax.minorticks_on()
    cbar1 = fig.colorbar(im1, ax=ax1, ticks=[-1, -1e-1, -1e-2, 1e-2, 1e-1, 1])
    cbar1.ax.minorticks_on()
    cbar1_p = fig.colorbar(im1_p, ax=axp1, ticks=[-1, -1e-1, -1e-2, 1e-2, 1e-1, 1])
    cbar1_p.ax.minorticks_on()
    cbar1_n = fig.colorbar(im1_n, ax=axn1, ticks=[-1, -1e-1, -1e-2, 1e-2, 1e-1, 1])
    cbar1_n.ax.minorticks_on()
else:
    cbar = fig.colorbar(im, ax=ax)
    cbar_p = fig.colorbar(im_p, ax=axp)
    cbar_n = fig.colorbar(im_n, ax=axn)
    cbar1 = fig.colorbar(im1, ax=ax1)
    cbar1_p = fig.colorbar(im1_p, ax=axp1)
    cbar1_n = fig.colorbar(im1_n, ax=axn1)

cbar.set_label(r"$\delta$ for {} (TECU)".format(datatype))
cbar_p.set_label(r"\delta for {} (TECU)".format(datatype))
cbar_n.set_label(r"\delta for {} (TECU)".format(datatype))
cbar1.set_label(r"\delta for {} (TECU)".format(datatype))
cbar1_p.set_label(r"\delta for {} (TECU)".format(datatype))
cbar1_n.set_label(r"\delta for {} (TECU)".format(datatype))
out_dir = "./delta-maps/"
axn.set_xlabel("Longitude (deg)")
ax.set_ylabel("Latitude (deg)")
axp.set_ylabel("Latitude (deg)")
axn.set_ylabel("Latitude (deg)")
axn1.set_xlabel("Universal Time (hours)")
plt.suptitle(date+r" $\delta$  parameter for {} map".format(datatype))
ax1.set_ylabel("Latitude (deg)")
axp1.set_ylabel("Latitude (deg)")
axn1.set_ylabel("Latitude (deg)")
axp.title.set_text(label + ". Previous day")
axp1.title.set_text(label)
ax.title.set_text(label + ". Event date")
axn.title.set_text(label+". Next day")

fig.set_size_inches(22, 18)


if substract == True:
    if log ==True:
        plt.savefig(out_dir+date+r"-$\delta$_{}_logmap_minus_background.".format(datatype)+formato)
    else:
        plt.savefig(out_dir+date+r"-$\delta$_{}_map_minus_background.".format(datatype)+formato)
else:
    if log==True:
        plt.savefig(out_dir+date+r"-$\delta$_{}_logmap.".format(datatype)+formato)
    else:
        plt.savefig(out_dir+date+r"-$\delta$_{}_map.".format(datatype)+formato)
#+END_SRC

#+NAME Energy vs time
#+BEGIN_SRC python :eval no :tangle ./energy_time.py

import numpy as np
import matplotlib.pyplot as plt
from astropy.table import Table
import seaborn as sns

# This program pretends to plot The kinetic energy of the meteors of the sample
# versus the respecting date.

# Read meteors database table

t = Table.read("meteors_database.tab", format="ascii")
t2 = Table.read("USG_meteors_database.tab", format="ascii")
# extract relevant data

ID , date, energy = t["ID"], t["Fecha"], t["Total energy recallibrated (kT)"]
ID_USG, date_USG, energy_USG = t2["ID"], t2["Fecha"], t2["Energia total (kT)"]
energy_arr = []
de = []

for e in energy:
    a, b = e.split("+/-")
    energy_arr.append(float(a))
    de.append(float(b))


# Make Boxplot (with whiskers)
sns.set_style("whitegrid")
GLM_energy = np.array(energy_arr)
USG_energy = t2["Energia total (kT)"]

plt.boxplot([GLM_energy, USG_energy], showfliers=False, patch_artist=True, 
             boxprops=dict(facecolor="red", color="red", alpha=0.5),         
             whiskerprops=dict(color="red"),
             capprops=dict(color="red"), 
             medianprops=dict(color="blue"))
plt.xticks([1, 2], ["GLM", "USG"])
plt.xlabel("Meteors sample")
plt.ylabel("Total energy (kT)")
plt.title("Meteors energy distribution (outliers removed)")
plt.savefig("energies_boxplot.pdf")
#+END_SRC

#+NAME Kp index vs time
#+BEGIN_SRC python :eval no :tangle ./kp_vs_time.py

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from astropy.table import Table
import pandas as pd

# This program pretends to plot the median Kp index of each event date and the two
# previous days versus date (and use errorbars to estimate variations along these days)
# Uses swarmplot (if i manage to do this kind of plot i will change the energy boxplot for this)

sns.set_style("whitegrid")
table = pd.read_csv("Kp_table.csv")
max_value = table["Max value"]
#colordict = {0:"green", 1:"green", 2:"green", 3:"green", 4:"yellow", 5:"red", 6:"red", 7:"red", 8:"red" , 9:"red"}
color_mask_1 = max_value < 4
color_mask_2 = max_value == 4
color_mask_3 = max_value > 4
#ax sns.swarmplot(x="Date", y="Median", data=table)
x = np.arange(len(table["Date"]))
y = table["Median"]
yerr1 = np.array([table["Variation"][color_mask_1], max_value[color_mask_1]-y[color_mask_1]])
yerr2 = np.array([table["Variation"][color_mask_2], max_value[color_mask_2]-y[color_mask_2]])
yerr3 = np.array([table["Variation"][color_mask_3], max_value[color_mask_3]-y[color_mask_3]])
plt.errorbar(x[color_mask_1], y[color_mask_1], fmt="o", yerr=yerr1, c="green")
plt.errorbar(x[color_mask_2], y[color_mask_2], fmt="o", yerr=yerr2, c="yellow")
plt.errorbar(x[color_mask_3], y[color_mask_3], fmt="o", yerr=yerr3, c="red")
xticks = [table["Date"][0], "", "", "", "", table["Date"][25], "", "", table["Date"][40]]
#xticks[0] = table["Date"][0]
#xticks[-1] = table["Date"][-1]
plt.xticks([0, 5, 10, 15, 20, 25, 30, 35, 40], labels=xticks)
plt.xlabel("Event date")
plt.ylabel("Kp index median")
plt.title("")
plt.savefig("Kp_index_dist.pdf")


#+END_SRC

#+NAME Energy Factor
#+BEGIN_SRC python :eval no :tangle ./energy_factor.py

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# The goal of this program is to estime the discrepancy factor between GLM energy estimations
# and the energy estimations by USG instruments in order to calibrate uncertainties to other
# events only registered by the GLM. For this we will make a linear fit between GLM and USG
# energies for events where data is available in both the GLM website and CNEOS fireballs website
# (Only three events meet this criteria: GLM-00, GLM-23 and GLM-Ven).
# The slope will be the correction factor and the residuals the uncertainties. 

sns.set_style("whitegrid")

# insert meteor energies

GLM_energies = np.array([1.0763569, 0.065099193, 3.1305469])
USG_energies = np.array([1.4, 0.076, 6])

GLM_uncertainties = np.array([0.18966796, 0.026813257, 0.28006880])
weights = 1./(1+GLM_uncertainties)

# Do the fit: p is an array with the fit coefficients, res is the residuals, rank, single values 
# and rcond are other outputs not used
p, res, rank, s_values, rcond = np.polyfit(GLM_energies, USG_energies, 1, w=weights, full=True)

# make a linar polynomial with the coefficients
poly = np.poly1d(p)
#poly_plus = np.poly1d([p[0]+res[0], p[1]])
#poly_minus = np.poly1d([p[0]-res[0], p[1]])

# make the plot
f = plt.figure()
ax1 = f.add_subplot(1, 2, 1)
ax2 = f.add_subplot(1, 2, 2)
ax1.errorbar(GLM_energies, USG_energies, xerr=GLM_uncertainties, fmt="g.", label="data points")
ax1.plot(GLM_energies, poly(GLM_energies), "k-", label="linear fit")
#ax1.set_xlabel("Meteor estimated kinetic energy by GLM (kilotons)", fontsize="small")
ax1.set_ylabel("Meteor estimated kinetic energy by USG sensors (kilotons)", fontsize="small")
ax1.text(0, 6.5, r"Linear fit: $y={:.3f}x - {:.3f}$".format(p[0], np.abs(p[1])), fontsize="small")
ax2.plot(GLM_energies, USG_energies-poly(GLM_energies), "go")
ax2.plot([GLM_energies[0], GLM_energies[0]], [0, USG_energies[0]-poly(GLM_energies[0])], "b--")
ax2.plot([GLM_energies[1], GLM_energies[1]], [0, USG_energies[1]-poly(GLM_energies[1])], "b--")
ax2.plot([GLM_energies[2], GLM_energies[2]], [0, USG_energies[2]-poly(GLM_energies[2])], "b--")
ax2.text(0, 1.05, "residuals (squares sum) = {:.4f}".format(res[0]), fontsize="small")
ax2.axhline(y=0, color="k")
ax2.set_ylim(-1, 1)
#ax2.set_xlabel("Meteor estimated kinetic energy by GLM (kilotons)", fontsize="small")
ax2.set_ylabel("Residuals")
f.text(0.5, 0.01, "Meteor estimated kinetic energy by GLM (kilotons)", ha='center', fontsize="small")
#plt.fill_between(GLM_energies, poly_minus(GLM_energies), poly_plus(GLM_energies), color="r", alpha = 0.2)
#plt.plot(GLM_energies, poly_minus(GLM_energies), "r--", alpha=0.2)
#plt.plot(GLM_energies, poly_plus(GLM_energies), "r--", alpha=0.2)
#plt.legend()
f.tight_layout()
plt.savefig("energy_fit.pdf")
#+END_SRC

#+NAME Kp index extractor
#+BEGIN_SRC python :eval no :tangle ./kp_index_file.py

# The goal of this program is to create a file containing the following data

#     Date   | Kp index median | Max Kp index |     Variation       |
#  ----------+-----------------+--------------+---------------------|
#  2000-01-01|  Number         | Above 4      |Median - min Kp index|
#  2000-01-02|  Number         | 4            |  Number             |
#  2000-01-03|  Number         |  Below 4     |  Number             |

# For use in another program. For this we must recycle some linecodes
# From our other Kp index program

import glob
import seaborn as sns
from astropy.table import Table
import numpy as np
import statistics as stats

def yesterday(date):
    """
    Enters any date and returns the previos day
    (is not as easy as you think). Limited to 1990
    and forward.
    """
    year, month, day = date.split("-") # Get year, month and day from date
    bisiesto = (year =="1992") | (year=="1996") | (year=="2000") | (year=="2004") | (year=="2008") | (year=="2012") | (year=="2016") | (year=="2020") 
    thirty_day_month = (month == "05") | (month == "07") | (month == "10")| (month == "12")
    if day == "01":
        if month == "01": # January 1st case
            pyear = str(int(year)-1)
            pmonth = "12"
            pday = "31"     
        else:
            pyear = year
            pmonth = str(int(month)-1)
            if int(pmonth) <10:
                pmonth="0"+pmonth
            if month == "03": # March 31th case
                if bisiesto== True:
                    pday = "29"
                else:
                    pday = "28"
            elif thirty_day_month ==True: # Previous month has 30 days
                pday = "30"
            else: # Previous month has 31 days
                pday = "31"
    else:
        pyear = year
        pmonth = month
        pday = str(int(day)-1)
        if int(pday) <10:
            pday = "0"+pday
    return(pyear+"-"+pmonth+"-"+pday)

# Create a list with the desired sample (dates)

#sample = ["1995-08-05", "1996-07-12", temporaly remove 1995 and 1996 meteors since their data format is sligthly different
sample = ["1997-10-09", "2000-01-18", "2000-08-25", "2005-11-15", "2015-07-19", "2019-02-01", "2019-05-23", "2019-07-18", "2019-08-10", "2020-04-28", "2019-10-03", "2019-10-09", "2019-11-16", "2019-11-17", "2019-11-19", "2019-11-26", "2019-12-04", "2019-12-15", "2019-12-29", "2020-01-03", "2020-01-06", "2019-06-22", "2021-03-31", "2020-12-29", "2020-01-15", "2020-02-12", "2020-03-03", "2020-03-31", "2020-04-08", "2020-04-18", "2020-04-20", "2020-04-25", "2020-05-08", "2020-07-15", "2020-08-07", "2020-09-13", "2020-09-30", "2020-11-16", "2020-11-17", "2020-12-19", "2020-12-23"] 

# open needed file(s)

#ftpfile = {"1995-08-05":"1995_DGD.txt", "1996-07-12":"1996_DGD.txt", 
ftpfile = {"1997-10-09":"1997_DGD.txt", "2000-01-18":"2000_DGD.txt", "2000-08-25":"2000_DGD.txt", "2005-11-15":"2005_DGD.txt", "2015-07-19":"2015_DGD.txt", "2019-02-01":"2019Q1_DGD.txt", "2019-05-23":"2019Q2_DGD.txt", "2019-07-18":"2019Q3_DGD.txt", "2019-08-10":"2019Q3_DGD.txt", "2020-04-28":"2020Q2_DGD.txt", "2019-10-03":"2019Q4_DGD.txt", "2019-10-09":"2019Q4_DGD.txt", "2019-11-16":"2019Q4_DGD.txt", "2019-11-17":"2019Q4_DGD.txt", "2019-11-19":"2019Q4_DGD.txt", "2019-11-26":"2019Q4_DGD.txt", "2019-12-04":"2019Q4_DGD.txt", "2019-12-15":"2019Q4_DGD.txt", "2019-12-29":"2019Q4_DGD.txt", "2020-01-03":"2020Q1_DGD.txt", "2020-01-06":"2020Q1_DGD.txt", "2019-06-22":"2019Q2_DGD.txt", "2021-03-31":"2021Q1_DGD.txt", "2020-12-29":"2020Q4_DGD.txt", "2020-01-15":"2020Q1_DGD.txt", "2020-02-12":"2020Q1_DGD.txt", "2020-03-03":"2020Q1_DGD.txt", "2020-03-31":"2020Q1_DGD.txt", "2020-04-08":"2020Q2_DGD.txt", "2020-04-18":"2020Q2_DGD.txt", "2020-04-20":"2020Q2_DGD.txt", "2020-04-25":"2020Q2_DGD.txt", "2020-05-08":"2020Q2_DGD.txt", "2020-07-15":"2020Q3_DGD.txt", "2020-08-07":"2020Q3_DGD.txt", "2020-09-13":"2020Q3_DGD.txt", "2020-09-30":"2020Q3_DGD.txt", "2020-11-16":"2020Q4_DGD.txt", "2020-11-17":"2020Q4_DGD.txt", "2020-12-19":"2020Q4_DGD.txt", "2020-12-23":"2020Q4_DGD.txt"}

# Declaring output variables

Kp_median = []
Kp_max = []
Kp_deviation = []


for ftp in ftpfile:
    f = open(ftpfile[ftp], "r")
    
    ## Skip first 12 rows
    
    f.readline()
    f.readline()
    f.readline()
    f.readline()
    f.readline()
    f.readline()
    f.readline()
    f.readline()
    f.readline()
    f.readline()
    f.readline()
    f.readline()
    
    ## Load data
    
    raw_data = f.readlines()
    
    # Select desired dates from the whole data
    
    kp = []
    Date = ftp
    Datep = yesterday(Date)
    Datepp = yesterday(Datep)
    for d in raw_data:
        k_date = d.split()[0:3]
        kdate = k_date[0]+"-"+ k_date[1]+"-"+k_date[2]
        if((kdate==Date)|(kdate==Datep)|(kdate==Datepp)):
            kp.append(d.split()[-8:])
    
    
    # Reshape array to be unidimensional
    
    Kp = np.array(kp).reshape(24,)
    
    # Convert array elements from strings to integers
    
    Kp = [int(k) for k in Kp]
    kp_median = stats.median(Kp)
    kp_max = max(Kp)
    kp_deviation = kp_median - min(Kp)
        
    Kp_median.append(kp_median)
    Kp_max.append(kp_max)
    Kp_deviation.append(kp_deviation)

#print(len(sample), len(Kp_median), len(Kp_deviation))
t = Table([sample, Kp_median, Kp_max, Kp_deviation], names=("Date", "Median", "Max value", "Variation"))
t.write("Kp_table.csv", format="csv", overwrite=True)
#+END_SRC

#+NAME TEC Detrender
#+BEGIN_SRC python :eval no :tangle ./TEC_detrender.py

import numpy as np
from astropy.table import Table
import argparse
import glob 
import matplotlib.pyplot as plt
from scipy.interpolate import interp1d
from scipy.signal import savgol_filter as savitsky
from scipy.stats import mode

# The goal of this progrma is to get detrended time series TEC curves using the method
# Described by Pradipta et al. 2015. We expect that the resulting detrended TEC data show
# ionospheric perturbations in our dataset.


def next_contact_point(x, y, x0, y0):
    """
    Estimate the next contact point into the Barrell roll curve (BRC)
    inputs:
    x: scaled time.
    y: scaled vTEC
    x0: x pivot point
    y0: y pivot point
    output:
    (xf, yf): coordinates of the next contact point
    """
    # Define region of interest
    R0 = 1 # Radius of the barrell roll. Unitary radius works pretty well
    ROI = (x > x0) & (x < x0 + 2*R0)
    # Delta_x and delta_y are the separation between the elements which belong to the ROI and (x0, y0)
    delta_x = x[ROI]-x0
    delta_y = y[ROI]-y0
    
    try:
        # calculating important angles
        theta = np.arctan2(delta_y, delta_x)
        cos_alpha = np.sqrt(delta_x**2 + delta_y**2)/(2*R0) 
        delta = np.arcsin(cos_alpha) - theta
        # Selecting the Next Contact Point (NCP)
        NCP = delta == min(delta) # The next contact point has the smallest angular distance delta
        xf, yf = x0+delta_x[NCP][0], y0+delta_y[NCP][0]
    except ValueError: # this happens because ROI is empty
        xf, yf = x[~ROI & (x>x0)][0], y[~ROI & (x>x0)][0] #The element we will use as next contact point
                                                          # is the first outside the ROI and greater than x0
    return xf, yf

def free_dep_signal(brc_x, brc_y, x, y):
    """
    Create the free depletion signal.
    Inputs:
    (brc_x, brc_y): Barrel roll curve coordinates
    (x, y): TEC curve 
    output:
    (xf, yf): free depletion signal
    """
    delta_1, delta_2 = 1, 3
    BRC_plus = brc_y + delta_1
    BRC_minus = brc_y - delta_2
    int_bplus = interp1d(brc_x, BRC_plus)
    int_bminus = interp1d(brc_x, BRC_minus)
    mask = (y < int_bplus(x)) & (y> int_bminus(x))
    xf, yf = x[mask], y[mask]
    return xf, yf

# ************************** Get window size for Savitzky-Golay Filter ************************

def get_window_size(x):
    """
    Get window size for the Savitzky-Golay filter. Must be an *odd* integer.
    This module basically substracts 1 if x is an even number and keeps the number if x is odd
    the output number is integer
    """
    return int(2*np.ceil(x/2.)-1)

def discontinuity(x):
    """
    Find discontinuities in any array
    """
    x_gradient = np.gradient(x)
    dx_mode = mode(x_gradient)[0][0]
    for dx in x_gradient:
        if dx > 2*dx_mode:
            flag = True
            break
        else:
            flag = False
    return flag

# **************************** Split discontine PRN *******************************************

def split_PRN(t, TEC):
    """
    Split a discontinuos PRN into pieces and return the biggest ones
    inputs:
    t, TEC: arrays to be split. t --> time , TEC --> vTEC
    outputs:
    output_t, output_TEC --> 2D arrays which contain the fragmented curve
    """

    index_discontinuity =[]
    gradient_t = np.gradient(t)
    for i, dt in enumerate(gradient_t):
        if dt > 0.01: # 0.01 is like 10 times the regular GPS frequency
            index_discontinuity.append(i) # collect the indices where time gradient is big enough
    split_t = np.split(t, index_discontinuity)
    split_TEC = np.split(TEC, index_discontinuity)
    output_t = []
    output_TEC =[]
    for s, tec in zip(split_t, split_TEC):
        if len(s) > 20: #if the subarray contain too few elements will be discarded
            output_t.append(s)
            output_TEC.append(tec)
    return output_t, output_TEC

# *************************** Read inputs from command line ***********************************

parser = argparse.ArgumentParser(
    description=""" Choose a file to work""")


parser.add_argument('--date', type=str, default='2000-01-01',
			       help='Choose date. Format: yyyy-mm-dd')

parser.add_argument("--formato", type=str, default="pdf", choices=("pdf", "png", "jpg"), 
                                help="Choose output format")
parser.add_argument("--starttime", type=str, default="00:00:00", help="Select the event start time")
parser.add_argument("--filterhigh", type=float, default=30, 
                     help="Filter the upper time interval of the TEC curve (in ninutes)")
parser.add_argument("--filterlow", type=float, default=10, 
                     help="Filter the lower time interval of the TEC curve (in ninutes)")

cmd_args = parser.parse_args()
date = cmd_args.date
formato = cmd_args.formato
start_time = cmd_args.starttime
filter_high = cmd_args.filterhigh
filter_low = cmd_args.filterlow

# ****************************** Read data file ************************************************

f = open("./data/2019-02-01/unpm032-2019-02-01.Cmn") # Test file until the program works
for i in range(4):
    f.readline()

raw_data = f.readlines()

# ****************************** Extract relevant information ***********************************

data = Table.read(raw_data, format="ascii")
hr, minute, sec = start_time.split(":")
time_hours = float(hr)+float(minute)/60. + float(sec)/3600.
time = data["Time"]
vTEC = data["Vtec"]
PRN = data["PRN"]
time_corrector = time < 0
time[time_corrector] = time[time_corrector] + 24.0
tau_0, zeta_0 = 2.0, 40.0
prn_array = np.unique(PRN)
for p in prn_array:
    PRN_mask = PRN == p
    selected_time = time[PRN_mask]
    selected_TEC = vTEC[PRN_mask]
    time_mask = (selected_time < time_hours + filter_high/60.) & (selected_time > time_hours-filter_low/60.)

# ******************************* Split the signal into fragments *********************************

    S_time, S_TEC = split_PRN(selected_time, selected_TEC)
#test plot
    for s, tec in zip(S_time, S_TEC):
        plt.plot(s, tec, "b.")
# ******************************* Start making BRC ***********************************************
        X, Y = s/tau_0, tec/zeta_0
        x_0, y_0 = X[0], Y[0]
        BRC_x = [x_0]
        BRC_y = [y_0]
        while(x_0 < X[-1]):
            xn, yn = next_contact_point(X, Y, x_0, y_0)
            BRC_x.append(xn)
            BRC_y.append(yn)
            x_0, y_0 = xn, yn

# ********************************** Making free deptetion signal ********************************
# Return to the TEC-time space
        brc_t, brc_vt = np.array(BRC_x)*tau_0, np.array(BRC_y)*zeta_0
#        fdp_vt = interp1d(brc_t, brc_vt) # The free depletion signal may be an interpolation of the BRC
        fdp_x, fdp_y = free_dep_signal(brc_t, brc_vt, s, tec)  
        plt.plot(brc_t, brc_vt, "r*")
        plt.plot(fdp_x, fdp_y)
#        plt.plot(s, fdp_vt(s))
# ********************************** Get trend using Savitzky-Golay filter ***********************
#        residuals = 1.0
#        ord=1
#        while(residuals > 0.15)|(ord <=10): # Use SG filter for the resulting fragments. Increase order of
                                        # fit until residuals become small enough
#            y_trend = savitsky(tec, window_length=get_window_size(len(tec)), polyorder=ord)
#            residuals = np.sum((y_trend-tec)**2)/len(tec)
#            ord=ord+1
#        plt.plot(s, y_trend, "r--")
#        print(residuals)
    plt.savefig("./TEC_tests/test_detrend_{}.pdf".format(p))
    plt.clf()
#plt.savefig("./TEC_tests/test_detrend_test.pdf")

 

#    print(p, len(X))
#if len(X) < 20: # TEC series with too few data will be considered "empty"
#    continue







#, vt = X*tau_0, Y*zeta_0




 
# ********************************** Plot test graph *********************************************
#    print(p, np.corrcoef(t, vt)[0][1])
#plt.plot(t, vt, "g.")


#plt.plot(t, y_trend, "m--")
#    plt.plot(X, Y, "g.")
#    plt.plot(BRC_x, BRC_y, "r*")
#    plt.fill_between(np.array(BRC_x), np.array(BRC_y)+1, np.array(BRC_y)-3, alpha=0.1) 
#    plt.axvline(time_hours, ls="--", c="k")



#+END_SRC
